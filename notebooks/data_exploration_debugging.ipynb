{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "import GPUtil\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import codecarbon\n",
    "from iesta.data.iesta_data import IESTAData, LABELS\n",
    "from iesta.data.huggingface_loader import IESTAHuggingFace\n",
    "from nlpaf.transformers.text_classification import TextClassification\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import argparse\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "\n",
    "def _apply_no_punc(row):\n",
    "    row[\"text_no_punc\"] = re.sub(r\"[^\\w\\s]\", \"\", row[\"text\"])\n",
    "    return row\n",
    "\n",
    "\n",
    "def profile_datasets(\n",
    "    ds_name: str = \"debateorg_w_effect_for_liberal\", lower: bool = False\n",
    "):\n",
    "    dataset_dict: DatasetDict = load_dataset(f\"notaphoenix/{ds_name}\")\n",
    "    dfs = []\n",
    "    for split, ds in dataset_dict.items():\n",
    "        print(split)\n",
    "        dfs.append(ds.to_pandas())\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    len(df)\n",
    "    # profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "    # df[\"text_low\"] = df[\"text\"].str.lower()\n",
    "    dissmiss_arr = []\n",
    "    with open(\"../data/dismiss_text.txt\", \"r\") as dismissedf:\n",
    "        dissmiss_arr = list(\n",
    "            pd.Series(dismissedf.read().splitlines()).str.lower()\n",
    "        )\n",
    "        dissmiss_arr = list(\n",
    "            set([re.sub(r\"[^\\w\\s]\", \"\", x) for x in dissmiss_arr])\n",
    "        )\n",
    "\n",
    "    df = df.apply(_apply_no_punc, axis=1)\n",
    "    df = df[~df[\"text_no_punc\"].str.lower().isin(dissmiss_arr)]\n",
    "    if lower:\n",
    "        df[\"text_low\"] = df[\"text\"].str.lower()\n",
    "        profile = ProfileReport(df[[\"text_low\"]], title=\"Profiling Report\")\n",
    "        profile.to_file(f\"../data/profilers/{ds_name}_low.html\")\n",
    "    else:\n",
    "        profile = ProfileReport(df[[\"text\"]], title=\"Profiling Report\")\n",
    "        profile.to_file(f\"../data/profilers/{ds_name}.html\")\n",
    "    return df, profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is typically needed once per notebook\n",
    "# %matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_datasets(\n",
    "    ds_name: str = \"debateorg_w_effect_for_liberal\", lower: bool = False\n",
    "):\n",
    "    dataset_dict: DatasetDict = load_dataset(f\"notaphoenix/{ds_name}\")\n",
    "    dfs = []\n",
    "    for split, ds in dataset_dict.items():\n",
    "        print(split)\n",
    "        dfs.append(ds.to_pandas())\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    len(df)\n",
    "    # profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "    # df[\"text_low\"] = df[\"text\"].str.lower()\n",
    "    dissmiss_arr = []\n",
    "    with open(\"../data/dismiss_text.txt\", \"r\") as dismissedf:\n",
    "        dissmiss_arr = list(\n",
    "            pd.Series(dismissedf.read().splitlines()).str.lower()\n",
    "        )\n",
    "        dissmiss_arr = list(\n",
    "            set([re.sub(r\"[^\\w\\s]\", \"\", x) for x in dissmiss_arr])\n",
    "        )\n",
    "\n",
    "    df = df.apply(_apply_no_punc, axis=1)\n",
    "    df = df[~df[\"text_no_punc\"].str.lower().isin(dissmiss_arr)]\n",
    "\n",
    "    df[\"num_tokens\"] = df[\"text\"].apply(lambda x: len(word_tokenize(x)))\n",
    "    df[\"num_chars\"] = df[\"text\"].apply(lambda x: len(x))\n",
    "\n",
    "    # df = df[df['num_tokens']>2]\n",
    "    # df = df[df['num_tokens']<=1600]\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    fig, axes = plt.subplots(figsize=(10, 7))\n",
    "    # Plot histogram\n",
    "    color = \"olive\"\n",
    "    for lbl, df_ in df.groupby([\"label\"]):\n",
    "        sns.histplot(\n",
    "            df_[\"num_chars\"], bins=50, color=color, label=lbl, stat=\"percent\"\n",
    "        )\n",
    "        color = \"skyblue\"\n",
    "\n",
    "    plt.title(f\"Histogram of Token Counts {ds_name} \")\n",
    "    plt.xlabel(\"Number of Tokens\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict: DatasetDict = load_dataset(\n",
    "    f\"notaphoenix/debateorg_w_effect_for_liberal_subset\"\n",
    ")\n",
    "\n",
    "dataset_dict = dataset_dict.remove_columns(\n",
    "    [\"author\", \"original_text\", \"category\", \"round\", \"debate_id\", \"idx\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lbl, df_ in lib.groupby([\"label\"]):\n",
    "    print(lbl)\n",
    "    prev = 0\n",
    "    for x in range(5, 2001, 295):\n",
    "        print(\n",
    "            f\"between {prev} and {x} (inclusive): \",\n",
    "            len(df_[(df_[\"num_tokens\"] > prev) & (df_[\"num_tokens\"] <= x)]),\n",
    "        )\n",
    "        prev = x\n",
    "    print(f\"<= 600: \", len(df_[(df_[\"num_tokens\"] <= 600)]))\n",
    "    print(f\"> 600: \", len(df_[(df_[\"num_tokens\"] > 600)]))\n",
    "for lbl, df_ in lib.groupby([\"label\"]):\n",
    "    print(lbl)\n",
    "    prev = 0\n",
    "    for x in range(20, 10000, 500):\n",
    "        print(\n",
    "            f\"between {prev} and {x} (inclusive): \",\n",
    "            len(df_[(df_[\"num_tokens\"] > prev) & (df_[\"num_tokens\"] <= x)]),\n",
    "        )\n",
    "        prev = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    \"debateorg_w_effect_for_liberal_subset\",\n",
    "    \"debateorg_w_effect_for_conservative_subset\",\n",
    "    \"debateorg_w_effect_for_liberal\",\n",
    "    \"debateorg_w_effect_for_conservative\",\n",
    "]\n",
    "\n",
    "\n",
    "for ds_name in dataset_names:\n",
    "    # profile_datasets(ds_name, lower=True)\n",
    "    plot_datasets(ds_name)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iesta.data.iesta_data import IESTAData, LABELS\n",
    "from iesta.data.huggingface_loader import IESTAHuggingFace\n",
    "\n",
    "conservative_data_obj = IESTAData(\n",
    "    ideology=\"conservative\",\n",
    "    keep_labels=LABELS.EFF_INEFF,\n",
    ")\n",
    "liberal_data_obj = IESTAData(\n",
    "    ideology=\"liberal\",\n",
    "    keep_labels=LABELS.EFF_INEFF,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_df, df = conservative_data_obj.split_iesta_dataset_by_debate(\n",
    "    True, profile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_df, df = liberal_data_obj.split_iesta_dataset_by_debate(True, profile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.index.name = \"idx\"\n",
    "df_[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"debate_id\",\n",
    "        \"p_name\",\n",
    "        \"top_effect\",\n",
    "        \"category\",\n",
    "        \"round\",\n",
    "        \"argument\",\n",
    "        \"cleaned_text\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.to_parquet(\"temp.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show iesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install -U ../\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iesta.data.iesta_data import IESTAData, LABELS\n",
    "from iesta.data.huggingface_loader import IESTAHuggingFace\n",
    "\n",
    "ideology = \"liberal\"\n",
    "data_obj = IESTAData(\n",
    "    ideology=ideology,\n",
    "    keep_labels=LABELS.EFF_INEFF,\n",
    ")\n",
    "hf = IESTAHuggingFace(data_obj, reload_preprocess=False)\n",
    "style_eval_data = hf.upload_w_labels(\n",
    "    is_for_style_classifier=False, force_reload=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset_dict import Dataset, DatasetDict\n",
    "\n",
    "\n",
    "# notaphoenix/debateorg_w_effect_for_liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\n",
    "    \"notaphoenix/debateorg_w_effect_for_liberal\", use_auth_token=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "counts_dict = {\"liberal\": None, \"conservative\": None}\n",
    "for ideology in [\"liberal\", \"conservative\"]:\n",
    "    print(f\"\\n###### {ideology.capitalize()} ###### \")\n",
    "    ds = load_dataset(\n",
    "        f\"notaphoenix/debateorg_w_effect_for_{ideology}\", use_auth_token=True\n",
    "    )\n",
    "    ds_2 = load_dataset(\n",
    "        f\"notaphoenix/debateorg_w_effect_for_{ideology}_subset\", use_auth_token=True\n",
    "    )\n",
    "    \n",
    "    for split in [\"training\", \"test\", \"validation\"]:\n",
    "        print(f\"\\n****** {split.capitalize()} ***** \")\n",
    "        dd = ds[split]\n",
    "    \n",
    "        print()\n",
    "        df = dd.to_pandas()[\"label\"].value_counts().to_frame() + ds_2[split].to_pandas()[\"label\"].value_counts().to_frame()\n",
    "        df = df.rename(columns={\"label\": split})\n",
    "        if counts_dict[ideology] is None:\n",
    "            counts_dict[ideology] = df\n",
    "        else:\n",
    "            counts_dict[ideology] = counts_dict[ideology].merge(df, right_index=True, left_index=True, )\n",
    "        \n",
    "        # liberal 36,880,  1,845\n",
    "        # liberal 36,880,  2,054\n",
    "    counts_dict[ideology] = counts_dict[ideology].T.rename(columns={0: f\"Ineffective_{ideology}\",\n",
    "                                                                    1: f\"effective_{ideology}\"})\n",
    "\n",
    "all_counts_df = counts_dict[\"conservative\"].merge(counts_dict[\"liberal\"], right_index=True, left_index=True, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts_df.to_csv(\"data/all_counts_splits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_2[split].to_pandas()[\"label\"].value_counts().to_frame() +dd.to_pandas()[\"label\"].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_2[split].to_pandas()[\"label\"].value_counts().to_frame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import itertools\n",
    "ideology = \"liberal\"\n",
    "idx_per_exp_dict = {}\n",
    "for path in glob(f\"data/llms_out/new/{ideology}_*.jsonl\"):\n",
    "    df = pd.read_json(path_or_buf=path, lines=True)\n",
    "    df = df.drop_duplicates(subset=[\"idx\"], keep=\"last\")\n",
    "    idx_per_exp_dict[path] = df['idx'].unique()\n",
    "\n",
    "    #print(f\"Path {path}: {len(df['idx'].unique())}\")\n",
    "\n",
    "exps = idx_per_exp_dict.keys()\n",
    "for n in range(2, len(exps)+1):\n",
    "    print(f\"############## {n} ###################\")\n",
    "    for subset in itertools.combinations(exps, n):\n",
    "        res = []\n",
    "        for e in subset: \n",
    "            if len(res )== 0:\n",
    "                res  = idx_per_exp_dict[e]\n",
    "            else:\n",
    "                res = [x for x in res if x in idx_per_exp_dict[e]]\n",
    "        print(f\"{subset}: {len(res)}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideology = \"conservative\"\n",
    "path = f\"data/llms_out/new/{ideology}_llamav2_1shot.jsonl\"\n",
    "\n",
    "\n",
    "df = pd.read_json(path_or_buf=path, lines=True)\n",
    "df = df.drop_duplicates(subset=[\"idx\"], keep=\"last\")\n",
    "df[[\"idx\"]].to_csv(f\"data/out/{ideology}_idx.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iesta_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
