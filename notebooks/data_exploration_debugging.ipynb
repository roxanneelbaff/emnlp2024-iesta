{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "import GPUtil\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import codecarbon\n",
    "from iesta.data.iesta_data import IESTAData, LABELS\n",
    "from iesta.data.huggingface_loader import IESTAHuggingFace\n",
    "from nlpaf.transformers.text_classification import TextClassification\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import argparse\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "\n",
    "def _apply_no_punc(row):\n",
    "    row[\"text_no_punc\"] = re.sub(r\"[^\\w\\s]\", \"\", row[\"text\"])\n",
    "    return row\n",
    "\n",
    "\n",
    "def profile_datasets(\n",
    "    ds_name: str = \"debateorg_w_effect_for_liberal\", lower: bool = False\n",
    "):\n",
    "    dataset_dict: DatasetDict = load_dataset(f\"notaphoenix/{ds_name}\")\n",
    "    dfs = []\n",
    "    for split, ds in dataset_dict.items():\n",
    "        print(split)\n",
    "        dfs.append(ds.to_pandas())\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    len(df)\n",
    "    # profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "    # df[\"text_low\"] = df[\"text\"].str.lower()\n",
    "    dissmiss_arr = []\n",
    "    with open(\"../data/dismiss_text.txt\", \"r\") as dismissedf:\n",
    "        dissmiss_arr = list(\n",
    "            pd.Series(dismissedf.read().splitlines()).str.lower()\n",
    "        )\n",
    "        dissmiss_arr = list(\n",
    "            set([re.sub(r\"[^\\w\\s]\", \"\", x) for x in dissmiss_arr])\n",
    "        )\n",
    "\n",
    "    df = df.apply(_apply_no_punc, axis=1)\n",
    "    df = df[~df[\"text_no_punc\"].str.lower().isin(dissmiss_arr)]\n",
    "    if lower:\n",
    "        df[\"text_low\"] = df[\"text\"].str.lower()\n",
    "        profile = ProfileReport(df[[\"text_low\"]], title=\"Profiling Report\")\n",
    "        profile.to_file(f\"../data/profilers/{ds_name}_low.html\")\n",
    "    else:\n",
    "        profile = ProfileReport(df[[\"text\"]], title=\"Profiling Report\")\n",
    "        profile.to_file(f\"../data/profilers/{ds_name}.html\")\n",
    "    return df, profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is typically needed once per notebook\n",
    "# %matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_datasets(\n",
    "    ds_name: str = \"debateorg_w_effect_for_liberal\", lower: bool = False\n",
    "):\n",
    "    dataset_dict: DatasetDict = load_dataset(f\"notaphoenix/{ds_name}\")\n",
    "    dfs = []\n",
    "    for split, ds in dataset_dict.items():\n",
    "        print(split)\n",
    "        dfs.append(ds.to_pandas())\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    len(df)\n",
    "    # profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "    # df[\"text_low\"] = df[\"text\"].str.lower()\n",
    "    dissmiss_arr = []\n",
    "    with open(\"../data/dismiss_text.txt\", \"r\") as dismissedf:\n",
    "        dissmiss_arr = list(\n",
    "            pd.Series(dismissedf.read().splitlines()).str.lower()\n",
    "        )\n",
    "        dissmiss_arr = list(\n",
    "            set([re.sub(r\"[^\\w\\s]\", \"\", x) for x in dissmiss_arr])\n",
    "        )\n",
    "\n",
    "    df = df.apply(_apply_no_punc, axis=1)\n",
    "    df = df[~df[\"text_no_punc\"].str.lower().isin(dissmiss_arr)]\n",
    "\n",
    "    df[\"num_tokens\"] = df[\"text\"].apply(lambda x: len(word_tokenize(x)))\n",
    "    df[\"num_chars\"] = df[\"text\"].apply(lambda x: len(x))\n",
    "\n",
    "    # df = df[df['num_tokens']>2]\n",
    "    # df = df[df['num_tokens']<=1600]\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    fig, axes = plt.subplots(figsize=(10, 7))\n",
    "    # Plot histogram\n",
    "    color = \"olive\"\n",
    "    for lbl, df_ in df.groupby([\"label\"]):\n",
    "        sns.histplot(\n",
    "            df_[\"num_chars\"], bins=50, color=color, label=lbl, stat=\"percent\"\n",
    "        )\n",
    "        color = \"skyblue\"\n",
    "\n",
    "    plt.title(f\"Histogram of Token Counts {ds_name} \")\n",
    "    plt.xlabel(\"Number of Tokens\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict: DatasetDict = load_dataset(\n",
    "    f\"notaphoenix/debateorg_w_effect_for_liberal_subset\"\n",
    ")\n",
    "\n",
    "dataset_dict = dataset_dict.remove_columns(\n",
    "    [\"author\", \"original_text\", \"category\", \"round\", \"debate_id\", \"idx\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lbl, df_ in lib.groupby([\"label\"]):\n",
    "    print(lbl)\n",
    "    prev = 0\n",
    "    for x in range(5, 2001, 295):\n",
    "        print(\n",
    "            f\"between {prev} and {x} (inclusive): \",\n",
    "            len(df_[(df_[\"num_tokens\"] > prev) & (df_[\"num_tokens\"] <= x)]),\n",
    "        )\n",
    "        prev = x\n",
    "    print(f\"<= 600: \", len(df_[(df_[\"num_tokens\"] <= 600)]))\n",
    "    print(f\"> 600: \", len(df_[(df_[\"num_tokens\"] > 600)]))\n",
    "for lbl, df_ in lib.groupby([\"label\"]):\n",
    "    print(lbl)\n",
    "    prev = 0\n",
    "    for x in range(20, 10000, 500):\n",
    "        print(\n",
    "            f\"between {prev} and {x} (inclusive): \",\n",
    "            len(df_[(df_[\"num_tokens\"] > prev) & (df_[\"num_tokens\"] <= x)]),\n",
    "        )\n",
    "        prev = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    \"debateorg_w_effect_for_liberal_subset\",\n",
    "    \"debateorg_w_effect_for_conservative_subset\",\n",
    "    \"debateorg_w_effect_for_liberal\",\n",
    "    \"debateorg_w_effect_for_conservative\",\n",
    "]\n",
    "\n",
    "\n",
    "for ds_name in dataset_names:\n",
    "    # profile_datasets(ds_name, lower=True)\n",
    "    plot_datasets(ds_name)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iesta.data.iesta_data import IESTAData, LABELS\n",
    "from iesta.data.huggingface_loader import IESTAHuggingFace\n",
    "\n",
    "conservative_data_obj = IESTAData(\n",
    "    ideology=\"conservative\",\n",
    "    keep_labels=LABELS.EFF_INEFF,\n",
    ")\n",
    "liberal_data_obj = IESTAData(\n",
    "    ideology=\"liberal\",\n",
    "    keep_labels=LABELS.EFF_INEFF,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_df, df = conservative_data_obj.split_iesta_dataset_by_debate(\n",
    "    True, profile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_df, df = liberal_data_obj.split_iesta_dataset_by_debate(True, profile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.index.name = \"idx\"\n",
    "df_[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"debate_id\",\n",
    "        \"p_name\",\n",
    "        \"top_effect\",\n",
    "        \"category\",\n",
    "        \"round\",\n",
    "        \"argument\",\n",
    "        \"cleaned_text\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.to_parquet(\"temp.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show iesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install -U ../\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'iesta.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39miesta\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39miesta_data\u001b[39;00m \u001b[39mimport\u001b[39;00m IESTAData, LABELS\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39miesta\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhuggingface_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m IESTAHuggingFace\n\u001b[0;32m      4\u001b[0m ideology \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mliberal\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'iesta.data'"
     ]
    }
   ],
   "source": [
    "from iesta.data.iesta_data import IESTAData, LABELS\n",
    "from iesta.data.huggingface_loader import IESTAHuggingFace\n",
    "\n",
    "ideology = \"liberal\"\n",
    "data_obj = IESTAData(\n",
    "        ideology=ideology,\n",
    "        keep_labels=LABELS.EFF_INEFF,\n",
    "    )\n",
    "hf = IESTAHuggingFace(data_obj, reload_preprocess=False)\n",
    "style_eval_data = hf.upload_w_labels(\n",
    "            is_for_style_classifier=False, force_reload=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dotenv was True\n"
     ]
    }
   ],
   "source": [
    "import iesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'iesta.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39miesta\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'iesta.data'"
     ]
    }
   ],
   "source": [
    "import iesta.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset_dict import Dataset, DatasetDict\n",
    "\n",
    "\n",
    "# notaphoenix/debateorg_w_effect_for_liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/elba_ro/.cache/huggingface/datasets/notaphoenix___parquet/notaphoenix--debateorg_w_effect_for_liberal-d0ad1689381f171f/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38675cb71f764a03874fdcdf666e7b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"notaphoenix/debateorg_w_effect_for_liberal\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'author', 'original_text', 'category', 'round', 'debate_id', 'idx'],\n",
       "        num_rows: 7704\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'author', 'original_text', 'category', 'round', 'debate_id', 'idx'],\n",
       "        num_rows: 3886\n",
       "    })\n",
       "    training: Dataset({\n",
       "        features: ['text', 'label', 'author', 'original_text', 'category', 'round', 'debate_id', 'idx'],\n",
       "        num_rows: 27135\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>author</th>\n",
       "      <th>original_text</th>\n",
       "      <th>category</th>\n",
       "      <th>round</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Con Now I know full good and well that most of...</td>\n",
       "      <td>0</td>\n",
       "      <td>jmlandf</td>\n",
       "      <td>\\n  \\r\\nCon  \\r\\nNow I know full good and well...</td>\n",
       "      <td>Science</td>\n",
       "      <td>0</td>\n",
       "      <td>.999...-is-equal-to-1/2/</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you for taking the Debate. 1. I plan on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>jmlandf</td>\n",
       "      <td>\\n  \\r\\nThank you for taking the Debate.  \\n  ...</td>\n",
       "      <td>Science</td>\n",
       "      <td>1</td>\n",
       "      <td>.999...-is-equal-to-1/2/</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have full BoP, .9r will represent .9 repeati...</td>\n",
       "      <td>0</td>\n",
       "      <td>SeventhProfessor</td>\n",
       "      <td>\\n  \\n  I have full BoP, .9r will represent .9...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>0</td>\n",
       "      <td>.999...-is-equal-to-one./1/</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For my first proof, I will take ,9r, and put i...</td>\n",
       "      <td>0</td>\n",
       "      <td>SeventhProfessor</td>\n",
       "      <td>\\n  \\n  For my first proof, I will take ,9r, a...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>1</td>\n",
       "      <td>.999...-is-equal-to-one./1/</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm pretty bored so I was wondering to post a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Biowza</td>\n",
       "      <td>\\n  \\r\\nI'm pretty bored so I was wondering to...</td>\n",
       "      <td>Science</td>\n",
       "      <td>0</td>\n",
       "      <td>.999...-is-exactly-equal-to-1/1/</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7699</th>\n",
       "      <td>gmail is nothin' in front of yahoo...yahoo is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>harshita123</td>\n",
       "      <td>\\n  \\r\\ngmail is nothin' in front of yahoo...y...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>0</td>\n",
       "      <td>yahoo-is-better-than-gmail.../1/</td>\n",
       "      <td>55283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7700</th>\n",
       "      <td>As a portal Yahoo is better than gmail. The re...</td>\n",
       "      <td>0</td>\n",
       "      <td>harshita123</td>\n",
       "      <td>\\n  \\r\\nAs a portal Yahoo is better than gmail...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>1</td>\n",
       "      <td>yahoo-is-better-than-gmail.../1/</td>\n",
       "      <td>55284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7701</th>\n",
       "      <td>The features I mentioned are'nt provided by gm...</td>\n",
       "      <td>0</td>\n",
       "      <td>harshita123</td>\n",
       "      <td>\\n  \\r\\nThe features I mentioned are'nt provid...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2</td>\n",
       "      <td>yahoo-is-better-than-gmail.../1/</td>\n",
       "      <td>55285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7702</th>\n",
       "      <td>My temper is shorter than the average citizen ...</td>\n",
       "      <td>0</td>\n",
       "      <td>MassiveDump</td>\n",
       "      <td>\\n  \\n  My temper is shorter than the average ...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>0</td>\n",
       "      <td>you-are-a-nice-person/1/</td>\n",
       "      <td>55300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7703</th>\n",
       "      <td>Nuff said.</td>\n",
       "      <td>0</td>\n",
       "      <td>orioleking1</td>\n",
       "      <td>\\n  \\r\\nNuff said.</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>0</td>\n",
       "      <td>you-are-a-nice-person/1/</td>\n",
       "      <td>55301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7704 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "0     Con Now I know full good and well that most of...      0   \n",
       "1     Thank you for taking the Debate. 1. I plan on ...      0   \n",
       "2     I have full BoP, .9r will represent .9 repeati...      0   \n",
       "3     For my first proof, I will take ,9r, and put i...      0   \n",
       "4     I'm pretty bored so I was wondering to post a ...      0   \n",
       "...                                                 ...    ...   \n",
       "7699  gmail is nothin' in front of yahoo...yahoo is ...      0   \n",
       "7700  As a portal Yahoo is better than gmail. The re...      0   \n",
       "7701  The features I mentioned are'nt provided by gm...      0   \n",
       "7702  My temper is shorter than the average citizen ...      0   \n",
       "7703                                         Nuff said.      0   \n",
       "\n",
       "                author                                      original_text  \\\n",
       "0              jmlandf  \\n  \\r\\nCon  \\r\\nNow I know full good and well...   \n",
       "1              jmlandf  \\n  \\r\\nThank you for taking the Debate.  \\n  ...   \n",
       "2     SeventhProfessor  \\n  \\n  I have full BoP, .9r will represent .9...   \n",
       "3     SeventhProfessor  \\n  \\n  For my first proof, I will take ,9r, a...   \n",
       "4               Biowza  \\n  \\r\\nI'm pretty bored so I was wondering to...   \n",
       "...                ...                                                ...   \n",
       "7699       harshita123  \\n  \\r\\ngmail is nothin' in front of yahoo...y...   \n",
       "7700       harshita123  \\n  \\r\\nAs a portal Yahoo is better than gmail...   \n",
       "7701       harshita123  \\n  \\r\\nThe features I mentioned are'nt provid...   \n",
       "7702       MassiveDump  \\n  \\n  My temper is shorter than the average ...   \n",
       "7703       orioleking1                                 \\n  \\r\\nNuff said.   \n",
       "\n",
       "           category  round                         debate_id    idx  \n",
       "0           Science      0          .999...-is-equal-to-1/2/     18  \n",
       "1           Science      1          .999...-is-equal-to-1/2/     19  \n",
       "2     Miscellaneous      0       .999...-is-equal-to-one./1/     20  \n",
       "3     Miscellaneous      1       .999...-is-equal-to-one./1/     21  \n",
       "4           Science      0  .999...-is-exactly-equal-to-1/1/     22  \n",
       "...             ...    ...                               ...    ...  \n",
       "7699     Technology      0  yahoo-is-better-than-gmail.../1/  55283  \n",
       "7700     Technology      1  yahoo-is-better-than-gmail.../1/  55284  \n",
       "7701     Technology      2  yahoo-is-better-than-gmail.../1/  55285  \n",
       "7702  Miscellaneous      0          you-are-a-nice-person/1/  55300  \n",
       "7703  Miscellaneous      0          you-are-a-nice-person/1/  55301  \n",
       "\n",
       "[7704 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for split in []\n",
    "dd = ds[\"validation\"]\n",
    "dd.to_pandas()['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iesta_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
