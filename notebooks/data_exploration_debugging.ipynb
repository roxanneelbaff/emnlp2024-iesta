{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "import GPUtil\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import codecarbon\n",
    "from iesta.data.iesta_data import IESTAData, LABELS\n",
    "from iesta.data.huggingface_loader import IESTAHuggingFace\n",
    "from nlpaf.transformers.text_classification import TextClassification\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import argparse\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "\n",
    "def _apply_no_punc(row):\n",
    "    row[\"text_no_punc\"] = re.sub(r\"[^\\w\\s]\", \"\", row[\"text\"])\n",
    "    return row\n",
    "\n",
    "\n",
    "def profile_datasets(\n",
    "    ds_name: str = \"debateorg_w_effect_for_liberal\", lower: bool = False\n",
    "):\n",
    "    dataset_dict: DatasetDict = load_dataset(f\"notaphoenix/{ds_name}\")\n",
    "    dfs = []\n",
    "    for split, ds in dataset_dict.items():\n",
    "        print(split)\n",
    "        dfs.append(ds.to_pandas())\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    len(df)\n",
    "    # profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "    # df[\"text_low\"] = df[\"text\"].str.lower()\n",
    "    dissmiss_arr = []\n",
    "    with open(\"../data/dismiss_text.txt\", \"r\") as dismissedf:\n",
    "        dissmiss_arr = list(\n",
    "            pd.Series(dismissedf.read().splitlines()).str.lower()\n",
    "        )\n",
    "        dissmiss_arr = list(\n",
    "            set([re.sub(r\"[^\\w\\s]\", \"\", x) for x in dissmiss_arr])\n",
    "        )\n",
    "\n",
    "    df = df.apply(_apply_no_punc, axis=1)\n",
    "    df = df[~df[\"text_no_punc\"].str.lower().isin(dissmiss_arr)]\n",
    "    if lower:\n",
    "        df[\"text_low\"] = df[\"text\"].str.lower()\n",
    "        profile = ProfileReport(df[[\"text_low\"]], title=\"Profiling Report\")\n",
    "        profile.to_file(f\"../data/profilers/{ds_name}_low.html\")\n",
    "    else:\n",
    "        profile = ProfileReport(df[[\"text\"]], title=\"Profiling Report\")\n",
    "        profile.to_file(f\"../data/profilers/{ds_name}.html\")\n",
    "    return df, profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is typically needed once per notebook\n",
    "# %matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_datasets(\n",
    "    ds_name: str = \"debateorg_w_effect_for_liberal\", lower: bool = False\n",
    "):\n",
    "    dataset_dict: DatasetDict = load_dataset(f\"notaphoenix/{ds_name}\")\n",
    "    dfs = []\n",
    "    for split, ds in dataset_dict.items():\n",
    "        print(split)\n",
    "        dfs.append(ds.to_pandas())\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    len(df)\n",
    "    # profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "    # df[\"text_low\"] = df[\"text\"].str.lower()\n",
    "    dissmiss_arr = []\n",
    "    with open(\"../data/dismiss_text.txt\", \"r\") as dismissedf:\n",
    "        dissmiss_arr = list(\n",
    "            pd.Series(dismissedf.read().splitlines()).str.lower()\n",
    "        )\n",
    "        dissmiss_arr = list(\n",
    "            set([re.sub(r\"[^\\w\\s]\", \"\", x) for x in dissmiss_arr])\n",
    "        )\n",
    "\n",
    "    df = df.apply(_apply_no_punc, axis=1)\n",
    "    df = df[~df[\"text_no_punc\"].str.lower().isin(dissmiss_arr)]\n",
    "\n",
    "    df[\"num_tokens\"] = df[\"text\"].apply(lambda x: len(word_tokenize(x)))\n",
    "    df[\"num_chars\"] = df[\"text\"].apply(lambda x: len(x))\n",
    "\n",
    "    # df = df[df['num_tokens']>2]\n",
    "    # df = df[df['num_tokens']<=1600]\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    fig, axes = plt.subplots(figsize=(10, 7))\n",
    "    # Plot histogram\n",
    "    color = \"olive\"\n",
    "    for lbl, df_ in df.groupby([\"label\"]):\n",
    "        sns.histplot(\n",
    "            df_[\"num_chars\"], bins=50, color=color, label=lbl, stat=\"percent\"\n",
    "        )\n",
    "        color = \"skyblue\"\n",
    "\n",
    "    plt.title(f\"Histogram of Token Counts {ds_name} \")\n",
    "    plt.xlabel(\"Number of Tokens\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict: DatasetDict = load_dataset(\n",
    "    f\"notaphoenix/debateorg_w_effect_for_liberal_subset\"\n",
    ")\n",
    "\n",
    "dataset_dict = dataset_dict.remove_columns(\n",
    "    [\"author\", \"original_text\", \"category\", \"round\", \"debate_id\", \"idx\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lbl, df_ in lib.groupby([\"label\"]):\n",
    "    print(lbl)\n",
    "    prev = 0\n",
    "    for x in range(5, 2001, 295):\n",
    "        print(\n",
    "            f\"between {prev} and {x} (inclusive): \",\n",
    "            len(df_[(df_[\"num_tokens\"] > prev) & (df_[\"num_tokens\"] <= x)]),\n",
    "        )\n",
    "        prev = x\n",
    "    print(f\"<= 600: \", len(df_[(df_[\"num_tokens\"] <= 600)]))\n",
    "    print(f\"> 600: \", len(df_[(df_[\"num_tokens\"] > 600)]))\n",
    "for lbl, df_ in lib.groupby([\"label\"]):\n",
    "    print(lbl)\n",
    "    prev = 0\n",
    "    for x in range(20, 10000, 500):\n",
    "        print(\n",
    "            f\"between {prev} and {x} (inclusive): \",\n",
    "            len(df_[(df_[\"num_tokens\"] > prev) & (df_[\"num_tokens\"] <= x)]),\n",
    "        )\n",
    "        prev = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    \"debateorg_w_effect_for_liberal_subset\",\n",
    "    \"debateorg_w_effect_for_conservative_subset\",\n",
    "    \"debateorg_w_effect_for_liberal\",\n",
    "    \"debateorg_w_effect_for_conservative\",\n",
    "]\n",
    "\n",
    "\n",
    "for ds_name in dataset_names:\n",
    "    # profile_datasets(ds_name, lower=True)\n",
    "    plot_datasets(ds_name)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iesta.data.iesta_data import IESTAData, LABELS\n",
    "from iesta.data.huggingface_loader import IESTAHuggingFace\n",
    "\n",
    "conservative_data_obj = IESTAData(\n",
    "    ideology=\"conservative\",\n",
    "    keep_labels=LABELS.EFF_INEFF,\n",
    ")\n",
    "liberal_data_obj = IESTAData(\n",
    "    ideology=\"liberal\",\n",
    "    keep_labels=LABELS.EFF_INEFF,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_df, df = conservative_data_obj.split_iesta_dataset_by_debate(\n",
    "    True, profile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_df, df = liberal_data_obj.split_iesta_dataset_by_debate(True, profile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.index.name = \"idx\"\n",
    "df_[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"debate_id\",\n",
    "        \"p_name\",\n",
    "        \"top_effect\",\n",
    "        \"category\",\n",
    "        \"round\",\n",
    "        \"argument\",\n",
    "        \"cleaned_text\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.to_parquet(\"temp.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show iesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install -U ../\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'iesta.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39miesta\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39miesta_data\u001b[39;00m \u001b[39mimport\u001b[39;00m IESTAData, LABELS\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39miesta\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhuggingface_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m IESTAHuggingFace\n\u001b[0;32m      4\u001b[0m ideology \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mliberal\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'iesta.data'"
     ]
    }
   ],
   "source": [
    "from iesta.data.iesta_data import IESTAData, LABELS\n",
    "from iesta.data.huggingface_loader import IESTAHuggingFace\n",
    "\n",
    "ideology = \"liberal\"\n",
    "data_obj = IESTAData(\n",
    "    ideology=ideology,\n",
    "    keep_labels=LABELS.EFF_INEFF,\n",
    ")\n",
    "hf = IESTAHuggingFace(data_obj, reload_preprocess=False)\n",
    "style_eval_data = hf.upload_w_labels(\n",
    "    is_for_style_classifier=False, force_reload=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dotenv was True\n"
     ]
    }
   ],
   "source": [
    "import iesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'iesta.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39miesta\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'iesta.data'"
     ]
    }
   ],
   "source": [
    "import iesta.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset_dict import Dataset, DatasetDict\n",
    "\n",
    "\n",
    "# notaphoenix/debateorg_w_effect_for_liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/elba_ro/.cache/huggingface/datasets/notaphoenix___parquet/notaphoenix--debateorg_w_effect_for_liberal-d0ad1689381f171f/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38675cb71f764a03874fdcdf666e7b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\n",
    "    \"notaphoenix/debateorg_w_effect_for_liberal\", use_auth_token=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'author', 'original_text', 'category', 'round', 'debate_id', 'idx'],\n",
       "        num_rows: 7704\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'author', 'original_text', 'category', 'round', 'debate_id', 'idx'],\n",
       "        num_rows: 3886\n",
       "    })\n",
       "    training: Dataset({\n",
       "        features: ['text', 'label', 'author', 'original_text', 'category', 'round', 'debate_id', 'idx'],\n",
       "        num_rows: 27135\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###### Liberal ###### \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/elba_ro/.cache/huggingface/datasets/notaphoenix___parquet/notaphoenix--debateorg_w_effect_for_liberal-d0ad1689381f171f/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37743337c0a040f287f5cb72ad8965e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Training ***** \n",
      "0    25824\n",
      "1     1311\n",
      "Name: label, dtype: int64\n",
      "\n",
      "****** Test ***** \n",
      "0    3719\n",
      "1     167\n",
      "Name: label, dtype: int64\n",
      "\n",
      "****** Validation ***** \n",
      "0    7337\n",
      "1     367\n",
      "Name: label, dtype: int64\n",
      "\n",
      "###### Conservative ###### \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15515a11cec944f08d57ff9ae5bda868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/767 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to C:/Users/elba_ro/.cache/huggingface/datasets/notaphoenix___parquet/notaphoenix--debateorg_w_effect_for_conservative-09f2d82db761569e/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5f1b7618014e5a9b657db390dceeba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9aba34978a048979a07aaa61920231a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/25.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b201991beb4da8941a8dd5630c76ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/11.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65127080f3764f56b510d9e588ee1283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/86.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4b2f956fdb41eea2f0a20172bc57b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5379aa00f7ad47d5971b273f0b48d112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/11464 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e536a78a8f14a0fb6c9ecae87d174d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5740 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b681e14b34c7414da273cd113cf99e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating training split:   0%|          | 0/40547 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to C:/Users/elba_ro/.cache/huggingface/datasets/notaphoenix___parquet/notaphoenix--debateorg_w_effect_for_conservative-09f2d82db761569e/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58fbfbd97b34ced933e9e08df6867b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Training ***** \n",
      "0    39163\n",
      "1     1384\n",
      "Name: label, dtype: int64\n",
      "\n",
      "****** Test ***** \n",
      "0    5500\n",
      "1     240\n",
      "Name: label, dtype: int64\n",
      "\n",
      "****** Validation ***** \n",
      "0    11034\n",
      "1      430\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for ideology in [\"liberal\", \"conservative\"]:\n",
    "    print(f\"\\n###### {ideology.capitalize()} ###### \")\n",
    "    ds = load_dataset(\n",
    "        f\"notaphoenix/debateorg_w_effect_for_{ideology}\", use_auth_token=True\n",
    "    )\n",
    "    for split in [\"training\", \"test\", \"validation\"]:\n",
    "        print(f\"\\n****** {split.capitalize()} ***** \")\n",
    "        dd = ds[split]\n",
    "        print(dd.to_pandas()[\"label\"].value_counts())\n",
    "\n",
    "        # liberal 36,880,  1,845\n",
    "        # liberal 36,880,  2,054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iesta_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
