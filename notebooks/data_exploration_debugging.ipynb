{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from comet_ml import Experiment\n",
    "import GPUtil\n",
    "import torch\n",
    "\n",
    "import os   \n",
    "import codecarbon\n",
    "from iesta.machine_learning.dataloader import IESTAData, LABELS\n",
    "from iesta.machine_learning.huggingface_loader import IESTAHuggingFace\n",
    "from nlpaf.transformers.text_classification import TextClassification\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import argparse\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "def _apply_no_punc(row):\n",
    "    row[\"text_no_punc\"] = re.sub(r'[^\\w\\s]', '', row[\"text\"])\n",
    "    return row\n",
    "\n",
    "def profile_datasets(ds_name:str = \"debateorg_w_effect_for_liberal\", lower:bool = False):\n",
    "    dataset_dict: DatasetDict = load_dataset(f\"notaphoenix/{ds_name}\")\n",
    "    dfs = []\n",
    "    for split, ds in dataset_dict.items():\n",
    "        print(split)\n",
    "        dfs.append(ds.to_pandas())\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    len(df)\n",
    "        #profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "    #df[\"text_low\"] = df[\"text\"].str.lower()\n",
    "    dissmiss_arr = []\n",
    "    with open(\"../data/dismiss_text.txt\", \"r\") as dismissedf:\n",
    "        dissmiss_arr = list(pd.Series(dismissedf.read().splitlines()).str.lower())\n",
    "        dissmiss_arr = list(set([re.sub(r'[^\\w\\s]', '', x) for x in dissmiss_arr]))\n",
    "    \n",
    "    \n",
    "    df = df.apply(_apply_no_punc, axis=1)\n",
    "    df = df[~df[\"text_no_punc\"].str.lower().isin(dissmiss_arr)]\n",
    "    if lower:\n",
    "        df[\"text_low\"] = df[\"text\"].str.lower()\n",
    "        profile = ProfileReport(df[[\"text_low\"]], title=\"Profiling Report\")\n",
    "        profile.to_file(f\"../data/profilers/{ds_name}_low.html\")\n",
    "    else:\n",
    "        profile = ProfileReport(df[[\"text\"]], title=\"Profiling Report\")\n",
    "        profile.to_file(f\"../data/profilers/{ds_name}.html\")\n",
    "    return df, profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is typically needed once per notebook\n",
    "#%matplotlib inline \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_datasets(ds_name:str = \"debateorg_w_effect_for_liberal\", lower:bool = False):\n",
    "    dataset_dict: DatasetDict = load_dataset(f\"notaphoenix/{ds_name}\")\n",
    "    dfs = []\n",
    "    for split, ds in dataset_dict.items():\n",
    "        print(split)\n",
    "        dfs.append(ds.to_pandas())\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    len(df)\n",
    "        #profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "    #df[\"text_low\"] = df[\"text\"].str.lower()\n",
    "    dissmiss_arr = []\n",
    "    with open(\"../data/dismiss_text.txt\", \"r\") as dismissedf:\n",
    "        dissmiss_arr = list(pd.Series(dismissedf.read().splitlines()).str.lower())\n",
    "        dissmiss_arr = list(set([re.sub(r'[^\\w\\s]', '', x) for x in dissmiss_arr]))\n",
    "    \n",
    "    \n",
    "    df = df.apply(_apply_no_punc, axis=1)\n",
    "    df = df[~df[\"text_no_punc\"].str.lower().isin(dissmiss_arr)]\n",
    "\n",
    "    df['num_tokens'] = df['text'].apply(lambda x: len(word_tokenize(x)))\n",
    "    df['num_chars'] = df['text'].apply(lambda x: len(x))\n",
    "\n",
    "    #df = df[df['num_tokens']>2]\n",
    "    #df = df[df['num_tokens']<=1600]\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    fig, axes = plt.subplots(figsize=(10,7))\n",
    "    # Plot histogram\n",
    "    color=\"olive\"\n",
    "    for lbl, df_ in df.groupby(['label']):\n",
    "        sns.histplot(df_['num_chars'], bins=50, color=color, label=lbl, stat=\"percent\")\n",
    "        color = \"skyblue\"\n",
    "\n",
    "    plt.title(f'Histogram of Token Counts {ds_name} ')\n",
    "    plt.xlabel(\"Number of Tokens\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend() \n",
    "    plt.show()\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = plot_datasets( \"debateorg_w_effect_for_liberal_subset\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lbl, df_ in lib.groupby(['label']):\n",
    "    print(lbl)\n",
    "    prev = 0\n",
    "    for x in range(5,2001,295):\n",
    "        print(f\"between {prev} and {x} (inclusive): \", len(df_[(df_['num_tokens']> prev) & (df_['num_tokens']<= x)]))\n",
    "        prev = x\n",
    "    print(f\"<= 600: \", len(df_[(df_['num_tokens']<= 600)]))\n",
    "    print(f\"> 600: \", len(df_[(df_['num_tokens']> 600)]))\n",
    "for lbl, df_ in lib.groupby(['label']):\n",
    "    print(lbl)\n",
    "    prev = 0\n",
    "    for x in range(20, 10000,500):\n",
    "        print(f\"between {prev} and {x} (inclusive): \", len(df_[(df_['num_tokens']> prev) & (df_['num_tokens']<= x)]))\n",
    "        prev = x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"debateorg_w_effect_for_liberal_subset\",\n",
    "                 \"debateorg_w_effect_for_conservative_subset\",\n",
    "                 \"debateorg_w_effect_for_liberal\",\n",
    "                 \"debateorg_w_effect_for_conservative\"]\n",
    "\n",
    "\n",
    "\n",
    "for ds_name in dataset_names:\n",
    "    #profile_datasets(ds_name, lower=True)\n",
    "    plot_datasets(ds_name)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iesta.machine_learning.dataloader import IESTAData, LABELS\n",
    "from iesta.machine_learning.huggingface_loader import IESTAHuggingFace\n",
    "conservative_data_obj = IESTAData(ideology=\"conservative\", keep_labels = LABELS.EFF_INEFF, )\n",
    "liberal_data_obj = IESTAData(ideology=\"liberal\", keep_labels = LABELS.EFF_INEFF, )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_data_obj.split_iesta_dataset_by_debate(True, profile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberal_data_obj.split_iesta_dataset_by_debate(True, profile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lib[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.index.name = 'idx'\n",
    "df_[[\"id\", \"debate_id\", \"p_name\", \"top_effect\", \"category\", \"round\", \"argument\", \"cleaned_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.to_parquet(\"temp.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iesta_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
