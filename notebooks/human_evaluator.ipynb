{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iesta.llms.generate import Generator\n",
    "import argparse\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "import iesta\n",
    "import iesta.llms\n",
    "import iesta.llms.models\n",
    "from iesta.llms.models import LlamaV2, ChatGpt\n",
    "\n",
    "import importlib\n",
    "importlib.reload(iesta)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "lib_ds = load_dataset(\"notaphoenix/debateorg_w_effect_for_liberal\")\n",
    "\n",
    "\n",
    "from transformers import LlamaTokenizer\n",
    "import numpy as np\n",
    "\n",
    "# Load LLAMA tokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "# Example text field\n",
    "text_field = lib_ds[\"training\"][\"text\"]\n",
    "\n",
    "# Tokenize the text field\n",
    "tokenized_texts = [tokenizer.tokenize(sentence) for sentence in text_field]\n",
    "\n",
    "# Count the number of tokens in each instance\n",
    "token_counts = [len(tokens) for tokens in tokenized_texts]\n",
    "\n",
    "# Calculate the median token count\n",
    "median_token_count = np.median(token_counts)\n",
    "\n",
    "print(\"Median token count:\", median_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/liberal_debate_arguments_w_effect.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"round\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_add_cols(row):\n",
    "    effect_dict_col = row[\"effect_count\"]\n",
    "    effect_dict = ast.literal_eval(ast.literal_eval(str(effect_dict_col)).decode('utf-8'))\n",
    "    total = 0\n",
    "    for eff, count in effect_dict.items():\n",
    "        row[eff] = count\n",
    "        total = total +count\n",
    "    row[\"total_votes\"] =    total \n",
    "    row[\"total_votes_up5\"] =    total > 5\n",
    "\n",
    "    return row\n",
    "df = df.apply(apply_add_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"effective\", \"ineffective\", \"provocative\", \"okay\"]].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df[[\"effective\", \"ineffective\", \"provocative\", \"okay\", \"total_votes\", \"total_votes_up5\"]]\n",
    "df_count = df_count.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_least_1 = len(df_count[df_count['effective'] >= 1])/len(df_count)\n",
    "at_least_1_in = len(df_count[df_count['ineffective'] >= 1])/len(df_count)\n",
    "print(\"# of debates: \", len(df_count))\n",
    "print(\"at_least_1:\", round( at_least_1*100, 1))\n",
    "print(\"at_least_1 INEFF:\", round( at_least_1_in*100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "def apply_has_majority(row):\n",
    "    majority = floor(row['total_votes'] / 2 ) +1\n",
    "    row[\"effective_majority\"] = row['effective'] >= majority\n",
    "    row[\"ineffective_majority\"] = row['ineffective'] >= majority\n",
    "    return row\n",
    "\n",
    "df_count = df_count.apply(apply_has_majority, axis = 1)\n",
    "\n",
    "majority_total = len(df_count[df_count['effective_majority']]) /len(df_count)\n",
    "majority_total_in = len(df_count[df_count['ineffective_majority']])/len(df_count)\n",
    "print(\"# of debates: \", len(df_count))\n",
    "print(\"majority:\", round( majority_total*100, 1))\n",
    "print(\"majority INEFF:\", round( majority_total_in*100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "def get_stats_per_effect(votes, df_votes, effect_val=\"effective\"):\n",
    "    vote_stat = {}\n",
    "    vote_stat[\"# of debates\"] = len(df_votes)\n",
    "    vote_stat[\"votes\"] = votes\n",
    "    majority = floor(votes / 2 ) +1\n",
    "    print(f\"Majority is {majority} for {votes}\")\n",
    "    for effect in range(1, min((majority+1), 4)):\n",
    "        vote_stat[f\"@{effect}\"] = len(df_votes[(df_votes[effect_val] >= effect )])\n",
    "        vote_stat[f\"{effect_val}_% @{effect}\"] =round((vote_stat[f\"@{effect}\"] / vote_stat[\"# of debates\"])* 100, 2)\n",
    "    vote_stat[f\">=Majority\"] = len(df_votes[(df_votes[effect_val] >= majority )])\n",
    "    vote_stat[f\"{effect_val}_% >=Majority\"] = round((vote_stat[f\">=Majority\"]  / vote_stat[\"# of debates\"])* 100, 2)\n",
    "    return vote_stat\n",
    "\n",
    "def get_stats_per_effect_votes_r_bigger(votes, df_votes, effect_val=\"effective\"):\n",
    "    vote_stat = {}\n",
    "    vote_stat[\"# of debates\"]  = 0\n",
    "    vote_stat[\"votes\"] = votes\n",
    "    for v, df_ in df_votes.groupby(\"total_votes\"): \n",
    "        dict_ = get_stats_per_effect(v, df_, effect_val)\n",
    "        if \"# of debates\" not in vote_stat.keys(): vote_stat[\"# of debates\"] =0\n",
    "        vote_stat[\"# of debates\"] = vote_stat[\"# of debates\"] + dict_[\"# of debates\"]\n",
    "        majority = floor(v / 2 ) +1\n",
    "        for effect in range(1, min((majority+1), 4)):\n",
    "            if f\"@{effect}\" not in vote_stat.keys(): vote_stat[f\"@{effect}\"] =0\n",
    "            vote_stat[f\"@{effect}\"] = vote_stat[f\"@{effect}\"] + dict_[f\"@{effect}\"] \n",
    "\n",
    "        if \">=Majority\" not in vote_stat.keys(): vote_stat[\">=Majority\"] =0\n",
    "        vote_stat[f\">=Majority\"] = vote_stat[f\">=Majority\"]  + dict_[f\">=Majority\"]\n",
    "    for effect in range(1, min((majority+1), 4)):\n",
    "        vote_stat[f\"{effect_val}_% @{effect}\"] =round((vote_stat[f\"@{effect}\"] / vote_stat[\"# of debates\"])* 100, 2)\n",
    "    vote_stat[f\"{effect_val}_% >=Majority\"] = round((vote_stat[f\">=Majority\"]  / vote_stat[\"# of debates\"])* 100, 2)\n",
    "    return vote_stat\n",
    "\n",
    "\n",
    "\n",
    "results_effective = []\n",
    "\n",
    "for votes, df_votes in df_count.groupby(\"total_votes\"):\n",
    "    results_effective.append(get_stats_per_effect(votes, df_votes, \"effective\"))\n",
    "\n",
    "results_ineffective = []\n",
    "\n",
    "for votes, df_votes in df_count.groupby(\"total_votes\"):\n",
    "    results_ineffective.append(get_stats_per_effect(votes, df_votes, \"ineffective\"))\n",
    "stats_df = pd.DataFrame(results_effective)\n",
    "stats_df.fillna(0.0, inplace=True)\n",
    "\n",
    "stats_ineffective_df = pd.DataFrame(results_ineffective)\n",
    "stats_ineffective_df.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ineffective_df = stats_ineffective_df[[\"# of debates\", \"votes\", \"ineffective_% @1\", \"ineffective_% >=Majority\"]]\n",
    "stats_ineffective_df.set_index([\"votes\", \"# of debates\"], inplace=True)\n",
    "stats_df = stats_df[[\"# of debates\", \"votes\", \"effective_% @1\", \"effective_% >=Majority\"]]\n",
    "stats_df.set_index([\"votes\", \"# of debates\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_liberal = stats_ineffective_df.merge(stats_df, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_liberal = stats_liberal[[\"ineffective_% @1\", \"effective_% @1\", \"ineffective_% >=Majority\", \"effective_% >=Majority\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effective_up5 = get_stats_per_effect_votes_r_bigger(6, df_count[df_count[\"total_votes_up5\"]], effect_val=\"effective\")\n",
    "ineffective_up5 = get_stats_per_effect_votes_r_bigger(6, df_count[df_count[\"total_votes_up5\"]], effect_val=\"ineffective\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effective_up5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ineffective_up5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "human_evaluation = pd.read_csv(\"data/human_evaluation/annotations.csv\")# (f\"data/human_evaluation/{ideology}_annotations.csv\")\n",
    "\n",
    "def apply_abstract(row):\n",
    "    for n in range(1,4):\n",
    "        for col in [f\"effectiveness_arg{n}\", f\"clarity_arg{n}\", f\"consistency_arg{n}\"]:\n",
    "            if col == \"consistency_arg1\":\n",
    "                continue\n",
    "            score_type = col.split(\"_\")[0]\n",
    "            row[f\"is_{col}\"] = row[col] >=3\n",
    "            row[f\"is_highly_{col}\"] = row[col] >=4\n",
    "    return row\n",
    "\n",
    "\n",
    "human_evaluation = human_evaluation.apply(apply_abstract, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>arg_tuple_id</th>\n",
       "      <th>annotation_date</th>\n",
       "      <th>effectiveness_arg1</th>\n",
       "      <th>effectiveness_arg2</th>\n",
       "      <th>effectiveness_arg3</th>\n",
       "      <th>clarity_arg1</th>\n",
       "      <th>clarity_arg2</th>\n",
       "      <th>clarity_arg3</th>\n",
       "      <th>...</th>\n",
       "      <th>is_clarity_arg2</th>\n",
       "      <th>is_highly_clarity_arg2</th>\n",
       "      <th>is_consistency_arg2</th>\n",
       "      <th>is_highly_consistency_arg2</th>\n",
       "      <th>is_effectiveness_arg3</th>\n",
       "      <th>is_highly_effectiveness_arg3</th>\n",
       "      <th>is_clarity_arg3</th>\n",
       "      <th>is_highly_clarity_arg3</th>\n",
       "      <th>is_consistency_arg3</th>\n",
       "      <th>is_highly_consistency_arg3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-09 22:37:59.284006+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>2024-02-09 22:38:31.381697+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-09 23:13:31.852903+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-11 15:46:02.001212+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-02-11 15:49:06.851714+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   a_id  user_id  arg_tuple_id                   annotation_date  \\\n",
       "0     1        4             0  2024-02-09 22:37:59.284006+00:00   \n",
       "1     2        5            50  2024-02-09 22:38:31.381697+00:00   \n",
       "2     3        6             0  2024-02-09 23:13:31.852903+00:00   \n",
       "3     4       11             0  2024-02-11 15:46:02.001212+00:00   \n",
       "4     5       11             1  2024-02-11 15:49:06.851714+00:00   \n",
       "\n",
       "   effectiveness_arg1  effectiveness_arg2  effectiveness_arg3  clarity_arg1  \\\n",
       "0                   1                   1                   3             1   \n",
       "1                   5                   5                   1             5   \n",
       "2                   3                   4                   4             4   \n",
       "3                   3                   3                   4             2   \n",
       "4                   3                   2                   4             4   \n",
       "\n",
       "   clarity_arg2  clarity_arg3  ...  is_clarity_arg2  is_highly_clarity_arg2  \\\n",
       "0             1             3  ...            False                   False   \n",
       "1             4             2  ...             True                    True   \n",
       "2             2             3  ...            False                   False   \n",
       "3             4             5  ...             True                    True   \n",
       "4             4             4  ...             True                    True   \n",
       "\n",
       "   is_consistency_arg2  is_highly_consistency_arg2  is_effectiveness_arg3  \\\n",
       "0                False                       False                   True   \n",
       "1                 True                       False                  False   \n",
       "2                 True                        True                   True   \n",
       "3                False                       False                   True   \n",
       "4                False                       False                   True   \n",
       "\n",
       "   is_highly_effectiveness_arg3  is_clarity_arg3  is_highly_clarity_arg3  \\\n",
       "0                         False             True                   False   \n",
       "1                         False            False                   False   \n",
       "2                          True             True                   False   \n",
       "3                          True             True                    True   \n",
       "4                          True             True                    True   \n",
       "\n",
       "   is_consistency_arg3  is_highly_consistency_arg3  \n",
       "0                 True                       False  \n",
       "1                 True                       False  \n",
       "2                 True                        True  \n",
       "3                 True                        True  \n",
       "4                 True                        True  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_evaluation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_ids = [13, 17]\n",
    "liberal_ids = [11, 15, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberal = human_evaluation[human_evaluation[\"user_id\"].isin(liberal_ids)]\n",
    "conservative = human_evaluation[human_evaluation[\"user_id\"].isin(conservative_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberal['favorite']\n",
    "\n",
    "def apply_fav(row):\n",
    "    row[f\"fav_arg{row['favorite']}\"] = 1\n",
    "    for i in range(1,4):\n",
    "        if i != row['favorite']:\n",
    "            row[f\"fav_arg{i}\"] = 0\n",
    "\n",
    "    return row\n",
    "liberal = liberal.apply(apply_fav, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative['favorite']\n",
    "\n",
    "conservative = conservative.apply(apply_fav, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a_id', 'annotation_date', 'arg_tuple_id', 'clarity_arg1',\n",
       "       'clarity_arg2', 'clarity_arg3', 'consistency_arg2', 'consistency_arg3',\n",
       "       'effectiveness_arg1', 'effectiveness_arg2', 'effectiveness_arg3',\n",
       "       'fav_arg1', 'fav_arg2', 'fav_arg3', 'favorite', 'is_clarity_arg1',\n",
       "       'is_clarity_arg2', 'is_clarity_arg3', 'is_consistency_arg2',\n",
       "       'is_consistency_arg3', 'is_effectiveness_arg1', 'is_effectiveness_arg2',\n",
       "       'is_effectiveness_arg3', 'is_highly_clarity_arg1',\n",
       "       'is_highly_clarity_arg2', 'is_highly_clarity_arg3',\n",
       "       'is_highly_consistency_arg2', 'is_highly_consistency_arg3',\n",
       "       'is_highly_effectiveness_arg1', 'is_highly_effectiveness_arg2',\n",
       "       'is_highly_effectiveness_arg3', 'user_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conservative.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = conservative['arg_tuple_id'].value_counts().rename_axis('unique_values').reset_index(name='count')\n",
    "arg_tuple_id_lst = df_[df_[\"count\"]>1][\"unique_values\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conservative = conservative[conservative[\"arg_tuple_id\"].isin(arg_tuple_id_lst)]\n",
    "len(conservative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_1annotator_per_row(df):\n",
    "    criteria_dict = {}\n",
    "    for user_id, df_ in df.sort_values(by=[\"user_id\", \"arg_tuple_id\"]).groupby([\"user_id\"]):\n",
    "        print(user_id)\n",
    "        for c in ['effectiveness_arg1', 'effectiveness_arg2', 'effectiveness_arg3',\n",
    "        'clarity_arg1', 'clarity_arg2', 'clarity_arg3', 'consistency_arg2',\n",
    "        'consistency_arg3', 'fav_arg1', 'fav_arg2', 'fav_arg3']:\n",
    "            if c  not in criteria_dict.keys(): criteria_dict[c]=  []\n",
    "            criteria_dict[c].append(df_[c].values.tolist())\n",
    "    return criteria_dict\n",
    "\n",
    "# a numpy array with rows as items and columns as raters\n",
    "\n",
    "# used for cohen kappa\n",
    "def get_rows_as_items_and_cols_as_raters(df, normalize = False):\n",
    "    criteria_dict = {}\n",
    "    for c in ['effectiveness_arg1', 'effectiveness_arg2', 'effectiveness_arg3',\n",
    "            'clarity_arg1', 'clarity_arg2', 'clarity_arg3', 'consistency_arg2',\n",
    "            'consistency_arg3', 'fav_arg1', 'fav_arg2', 'fav_arg3']:\n",
    "        df_ = df[[c,\"arg_tuple_id\", \"user_id\" ]].sort_values([\"arg_tuple_id\", \"user_id\"])\n",
    "        def do_normalize(row):\n",
    "            if row[c] <3:\n",
    "                row[c] = 0\n",
    "            else: row[c] = 1\n",
    "            return row\n",
    "        if normalize and not c.startswith(\"fav_\"):\n",
    "            df_ = df_.apply(do_normalize, axis = 1)\n",
    "        pivot_df = df_.pivot(index='arg_tuple_id', columns='user_id', values=c)\n",
    "        ratings_array = pivot_df.to_numpy()\n",
    "\n",
    "        criteria_dict[c] =  ratings_array\n",
    "    return criteria_dict\n",
    "\n",
    "\n",
    "def get_rows_as_items_and_cols_as_raters(df, normalize = False):\n",
    "    criteria_dict = {}\n",
    "    for c in ['effectiveness_arg1', 'effectiveness_arg2', 'effectiveness_arg3',\n",
    "            'clarity_arg1', 'clarity_arg2', 'clarity_arg3', 'consistency_arg2',\n",
    "            'consistency_arg3',  'fav_arg1', 'fav_arg2', 'fav_arg3']:\n",
    "        df_ = df[[c,\"arg_tuple_id\", \"user_id\" ]].sort_values([\"arg_tuple_id\", \"user_id\"])\n",
    "        def do_normalize(row):\n",
    "            if row[c] <3:\n",
    "                row[c] = 0\n",
    "            else: row[c] = 1\n",
    "            return row\n",
    "        if normalize and not c.startswith(\"fav_\"):\n",
    "            df_ = df_.apply(do_normalize, axis = 1)\n",
    "        pivot_df = df_.pivot(index='arg_tuple_id', columns='user_id', values=c)\n",
    "        ratings_array = pivot_df.to_numpy()\n",
    "\n",
    "        criteria_dict[c] =  ratings_array\n",
    "    return criteria_dict\n",
    "\n",
    "            \n",
    "    \n",
    "def getrow_as_item_rater_df(df, normalize = False):\n",
    "    criteria_dict = {}\n",
    "    for c in ['effectiveness_arg1', 'effectiveness_arg2', 'effectiveness_arg3',\n",
    "            'clarity_arg1', 'clarity_arg2', 'clarity_arg3', 'consistency_arg2',\n",
    "            'consistency_arg3', 'fav_arg1', 'fav_arg2', 'fav_arg3']:\n",
    "        df_ = df[[c,\"arg_tuple_id\", \"user_id\" ]].sort_values([\"arg_tuple_id\", \"user_id\"])\n",
    "\n",
    "\n",
    "        \n",
    "        def do_normalize(row):\n",
    "            \n",
    "            if row[c] <3:\n",
    "                row[c] = 0\n",
    "            #elif row[c] >3: row[c] = 3\n",
    "            else: row[c] = 1\n",
    "            return row\n",
    "        if normalize and not c.startswith(\"fav_\"):\n",
    "            df_ = df_.apply(do_normalize, axis = 1)\n",
    "\n",
    "        res_arr = []\n",
    "        for _, row in df_.iterrows():\n",
    "            res_arr.append({\n",
    "                \"Item\": row[\"arg_tuple_id\"],\n",
    "                \"Rater\": row[\"user_id\"],\n",
    "                \"Rating\": row[c] \n",
    "            }\n",
    "            )\n",
    "        criteria_dict[c] =  pd.DataFrame(res_arr)\n",
    "    return criteria_dict\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip  -q install pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chen KAPPA effectiveness_arg1: \t 0.2631046019976209\n",
      "chen KAPPA effectiveness_arg2: \t 0.11890838206627681\n",
      "chen KAPPA effectiveness_arg3: \t -0.04401154401154398\n",
      "chen KAPPA clarity_arg1: \t 0.10823090353806819\n",
      "chen KAPPA clarity_arg2: \t 0.07210698117771856\n",
      "chen KAPPA clarity_arg3: \t 0.08515130190007043\n",
      "chen KAPPA consistency_arg2: \t 0.1257705073494547\n",
      "chen KAPPA consistency_arg3: \t -0.020776874435411097\n",
      "chen KAPPA fav_arg1: \t 0.0357142857142857\n",
      "chen KAPPA fav_arg2: \t 0.1263398892310064\n",
      "chen KAPPA fav_arg3: \t 0.047615382831141084\n",
      "fleiss kappa\n",
      "effectiveness_arg1: \t 0.25280199252801977\n",
      "effectiveness_arg2: \t 0.11616161616161595\n",
      "effectiveness_arg3: \t -0.061477222467934606\n",
      "clarity_arg1: \t 0.06524926686216993\n",
      "clarity_arg2: \t 0.07355418304323424\n",
      "clarity_arg3: \t 0.1008991008991018\n",
      "consistency_arg2: \t 0.08133971291866034\n",
      "consistency_arg3: \t -0.024159663865545734\n",
      "fav_arg1: \t 0.0036231884057967025\n",
      "fav_arg2: \t 0.12424740010946904\n",
      "fav_arg3: \t 0.040000000000000036\n",
      "\n",
      "icc\n",
      "Index(['Item', 'Rater', 'Rating'], dtype='object')\n",
      "effectiveness_arg1: \t 0.278\n",
      "Index(['Item', 'Rater', 'Rating'], dtype='object')\n",
      "effectiveness_arg2: \t 0.121\n",
      "Index(['Item', 'Rater', 'Rating'], dtype='object')\n",
      "effectiveness_arg3: \t -0.042\n",
      "Index(['Item', 'Rater', 'Rating'], dtype='object')\n",
      "clarity_arg1: \t 0.127\n",
      "Index(['Item', 'Rater', 'Rating'], dtype='object')\n",
      "clarity_arg2: \t 0.078\n",
      "Index(['Item', 'Rater', 'Rating'], dtype='object')\n",
      "clarity_arg3: \t 0.121\n",
      "Index(['Item', 'Rater', 'Rating'], dtype='object')\n",
      "consistency_arg2: \t 0.175\n",
      "Index(['Item', 'Rater', 'Rating'], dtype='object')\n",
      "consistency_arg3: \t -0.024\n",
      "Index(['Item', 'Rater', 'Rating'], dtype='object')\n",
      "fav_arg1: \t 0.06\n",
      "Index(['Item', 'Rater', 'Rating'], dtype='object')\n",
      "fav_arg2: \t 0.129\n",
      "Index(['Item', 'Rater', 'Rating'], dtype='object')\n",
      "fav_arg3: \t 0.048\n",
      "\n",
      "\n",
      "tau\n",
      "effectiveness_arg1: \t 0.016783566595034546\n",
      "effectiveness_arg2: \t 0.007313972994395378\n",
      "effectiveness_arg3: \t -0.003402069087198859\n",
      "clarity_arg1: \t 0.007349818951341622\n",
      "clarity_arg2: \t 0.004832377973423638\n",
      "clarity_arg3: \t 0.007210884353741497\n",
      "consistency_arg2: \t 0.010142542485649064\n",
      "consistency_arg3: \t -0.0012392758478562413\n",
      "fav_arg1: \t nan\n",
      "fav_arg2: \t 0.007696229660520904\n",
      "fav_arg3: \t 0.002824503597043532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'effectiveness_arg1': 0.016783566595034546,\n",
       " 'effectiveness_arg2': 0.007313972994395378,\n",
       " 'effectiveness_arg3': -0.003402069087198859,\n",
       " 'clarity_arg1': 0.007349818951341622,\n",
       " 'clarity_arg2': 0.004832377973423638,\n",
       " 'clarity_arg3': 0.007210884353741497,\n",
       " 'consistency_arg2': 0.010142542485649064,\n",
       " 'consistency_arg3': -0.0012392758478562413,\n",
       " 'fav_arg1': nan,\n",
       " 'fav_arg2': 0.007696229660520904,\n",
       " 'fav_arg3': 0.002824503597043532}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COHEN's KAPPA\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import itertools\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau\n",
    "import pandas as pd\n",
    "\n",
    "def get_avg_pairwise_cohen_kappa(ratings):\n",
    "\n",
    "    raters_pair = list(itertools.combinations(range(0, len(ratings.T)), 2))\n",
    "\n",
    "    # Assuming 'ratings' is a numpy array with rows as items and columns as raters\n",
    "    kappas = 0.0\n",
    "    pari = 0\n",
    "    for pair in raters_pair:\n",
    "        kappas = kappas + cohens_kappa(ratings[:, pair[0]], ratings[:, pair[1]]).kappa\n",
    "        pari = pari +1\n",
    "    assert pari == 1\n",
    "    average_kappa = kappas / pari\n",
    "    return average_kappa\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_kappa_per_feature(df, normalize=False):\n",
    "    ratings_per_criteria = get_rows_as_items_and_cols_as_raters(df, normalize)\n",
    "    results = {}\n",
    "    for criteria, ratings in ratings_per_criteria.items():\n",
    "        res = get_avg_pairwise_cohen_kappa(ratings)\n",
    "        print(f\"cohen KAPPA {criteria}: \\t {res}\")\n",
    "        results[criteria] = res\n",
    "    return results\n",
    "\n",
    "get_kappa_per_feature(conservative, True)\n",
    "#get_kappa_per_feature(conservative)\n",
    "\n",
    "\n",
    "def get_fleiss_kappa_score(ratings):\n",
    "    rating_counts = np.apply_along_axis(lambda x: np.bincount(x, minlength=2), axis=1, arr=ratings)\n",
    "    return fleiss_kappa(rating_counts)\n",
    "\n",
    "def get_fleiss_kappa_per_feature(df, normalize=False):\n",
    "    ratings_per_criteria = get_rows_as_items_and_cols_as_raters(df, normalize)\n",
    "    results = {}\n",
    "    for criteria, ratings in ratings_per_criteria.items():\n",
    "        res = get_fleiss_kappa_score(ratings)\n",
    "        print(f\"{criteria}: \\t {res}\")\n",
    "        results[criteria] = res\n",
    "    return results\n",
    "print(\"fleiss kappa\")\n",
    "get_fleiss_kappa_per_feature(liberal, True)\n",
    "#get_kappa_per_feature(conservative)\n",
    "\n",
    "\n",
    "\n",
    "def get_icc(ratings_df, c):\n",
    "    # Convert numpy array 'ratings' to pandas DataFrame\n",
    "    # ratings_df = pd.DataFrame(ratings)\n",
    "     # Optionally, add an 'Item' column if your dataset doesn't have one\n",
    "    # ratings_df['Item'] = range(1, len(ratings_df) + 1)\n",
    "    # ratings_df.set_index('Item', inplace=True)\n",
    "    # ratings_df = pd.melt(ratings_df.reset_index(), id_vars='Item', var_name='Rater', value_name='Rating')\n",
    "\n",
    "    print(ratings_df.columns)\n",
    "    # Calculate ICC\n",
    "    icc = pg.intraclass_corr(data=ratings_df, targets='Item', raters='Rater', ratings=\"Rating\").round(3)\n",
    "    return icc.at[2, 'ICC']  # Using ICC(3, k) for consistency/agreement\n",
    "\n",
    "def get_icc_per_feature(df, normalize=False):\n",
    "    ratings_per_criteria = getrow_as_item_rater_df(df, normalize)\n",
    "    results = {}\n",
    "    for criteria, ratings in ratings_per_criteria.items():\n",
    "        res = get_icc(ratings, criteria)\n",
    "        print(f\"{criteria}: \\t {res}\")\n",
    "        results[criteria] = res\n",
    "    return results\n",
    "\n",
    "print(\n",
    "\n",
    ")\n",
    "print(\"icc\")\n",
    "get_icc_per_feature(liberal, True)\n",
    "# get_icc_per_feature(conservative)\n",
    "# get_rows_as_items_and_cols_as_raters(liberal, False)\n",
    "\n",
    "def get_kendall_tau(ratings_df):\n",
    "    \n",
    "\n",
    "    # Convert numpy array 'ratings' to pandas DataFrame and rank the ratings\n",
    "    # ratings_df = pd.DataFrame(ratings)\n",
    "    # Optionally, add an 'Item' column if your dataset doesn't have one\n",
    "    # ratings_df['Item'] = range(1, len(ratings_df) + 1)\n",
    "    # ratings_df.set_index('Item', inplace=True)\n",
    "\n",
    "    ratings_df = ratings_df.rank()\n",
    "    # Calculate Kendall's W\n",
    "    num_items = len(ratings_df)\n",
    "    num_raters = len(ratings_df.columns)\n",
    "    rank_sum_squared = sum(ratings_df.sum() ** 2)\n",
    "    return (12 * rank_sum_squared - 3 * num_items**2 * (num_raters+1)**2) / (num_items**2 * (num_raters**3 - num_raters))\n",
    "\n",
    "def get_kendallstau_per_feature(df, normalize=False):\n",
    "    ratings_per_criteria = getrow_as_item_rater_df(df, normalize)\n",
    "    results = {}\n",
    "    for criteria, ratings in ratings_per_criteria.items():\n",
    "        res = get_kendall_tau(ratings)\n",
    "        print(f\"{criteria}: \\t {res}\")\n",
    "        results[criteria] = res\n",
    "    return results\n",
    "\n",
    "print(\n",
    "\n",
    ")\n",
    "#print(\"KANDALL TAU\")\n",
    "#get_kendallstau_per_feature(liberal, True)\n",
    "\n",
    "\n",
    "\n",
    "def get_avg_pairwise_tau(ratings):\n",
    "\n",
    "    raters_pair = list(itertools.combinations(range(0, len(ratings.T)), 2))\n",
    "\n",
    "    # Assuming 'ratings' is a numpy array with rows as items and columns as raters\n",
    "    tau = 0.0\n",
    "    for pair in raters_pair:\n",
    "        tau = tau + kendalltau(ratings[:, pair[0]], ratings[:, pair[1]])[0]\n",
    "\n",
    "    average_tau = tau / len(ratings)\n",
    "    return average_tau\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_avgtau_per_feature(df, normalize=False):\n",
    "    ratings_per_criteria = get_rows_as_items_and_cols_as_raters(df, normalize)\n",
    "    results = {}\n",
    "    for criteria, ratings in ratings_per_criteria.items():\n",
    "        res = get_avg_pairwise_tau(ratings)\n",
    "        print(f\"{criteria}: \\t {res}\")\n",
    "        results[criteria] = res\n",
    "    return results\n",
    "print()\n",
    "print(\"tau\")\n",
    "get_avgtau_per_feature(liberal, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2]\n",
      " [ 5  6]\n",
      " [ 9 10]\n",
      " [13 14]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example NumPy array\n",
    "array = np.array([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12],\n",
    "    [13, 14, 15, 16]\n",
    "])\n",
    "\n",
    "# Specify the row indices and column indices you want to select\n",
    "row_indices = range(len(array)) # Selecting the 1st and 3rd rows (0-indexed)\n",
    "col_indices = [1, 3]  # Selecting the 2nd and 4th columns (0-indexed)\n",
    "pair = (0,1)\n",
    "# Using advanced indexing to select specific rows and columns\n",
    "\n",
    "print(selected_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting krippendorff\n",
      "  Downloading krippendorff-0.6.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.21 in /Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from krippendorff) (1.26.4)\n",
      "Downloading krippendorff-0.6.1-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: krippendorff\n",
      "Successfully installed krippendorff-0.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages/statsmodels/stats/inter_rater.py:504: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  self['z_value'] = self['kappa'] / self['std_kappa0']\n",
      "/Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages/statsmodels/stats/inter_rater.py:357: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  kappa = (agree / nobs - agree_exp) / (1 - agree_exp)\n",
      "/Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages/statsmodels/stats/inter_rater.py:372: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  var_kappa0 /= (1 - agree_exp)**2 * nobs\n",
      "/Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages/statsmodels/stats/inter_rater.py:421: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  kappa_max = (np.minimum(freq_row, freq_col).sum() - agree_exp) / \\\n",
      "/Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages/statsmodels/stats/inter_rater.py:501: RuntimeWarning: invalid value encountered in sqrt\n",
      "  self['std_kappa'] = np.sqrt(self['var_kappa'])\n",
      "/Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages/statsmodels/stats/inter_rater.py:504: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  self['z_value'] = self['kappa'] / self['std_kappa0']\n",
      "/Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages/statsmodels/stats/inter_rater.py:357: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  kappa = (agree / nobs - agree_exp) / (1 - agree_exp)\n",
      "/Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages/statsmodels/stats/inter_rater.py:372: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  var_kappa0 /= (1 - agree_exp)**2 * nobs\n",
      "/Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages/statsmodels/stats/inter_rater.py:421: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  kappa_max = (np.minimum(freq_row, freq_col).sum() - agree_exp) / \\\n",
      "/Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages/statsmodels/stats/inter_rater.py:504: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  self['z_value'] = self['kappa'] / self['std_kappa0']\n",
      "/Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages/statsmodels/stats/inter_rater.py:357: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  kappa = (agree / nobs - agree_exp) / (1 - agree_exp)\n",
      "/Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages/statsmodels/stats/inter_rater.py:372: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  var_kappa0 /= (1 - agree_exp)**2 * nobs\n",
      "/Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages/statsmodels/stats/inter_rater.py:421: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  kappa_max = (np.minimum(freq_row, freq_col).sum() - agree_exp) / \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixtral8x7B_Conservative KAPPA:{'effectiveness': 0.7488792221838781, 'clarity': 0.4537629581658334, 'consistency': 0.5621204838743589, 'fav': 0.4814325824941164}, FULL:{'effectiveness': 0.79, 'clarity': 0.82, 'consistency': 0.86, 'fav': 0.52} \n",
      "\n",
      "Mixtral8x7B_Liberal KAPPA:{'effectiveness': 0.6480084237531528, 'clarity': 0.5779263725692295, 'consistency': 0.5425588416913013, 'fav': 0.2663502612312645}, FULL:{'effectiveness': 0.75, 'clarity': 0.83, 'consistency': 0.86, 'fav': 0.34} \n",
      "\n",
      "GPT4_Liberal KAPPA:{'effectiveness': 0.6612294508225687, 'clarity': 0.5188257058969797, 'consistency': 0.8777967618582703, 'fav': 0.5261943102522812}, FULL:{'effectiveness': 0.69, 'clarity': 0.73, 'consistency': 0.91, 'fav': 0.52} \n",
      "\n",
      "GPT4_Conservative KAPPA:{'effectiveness': 0.6028897878695607, 'clarity': 0.5036028875441055, 'consistency': 0.8921541011545728, 'fav': 0.5061513687600645}, FULL:{'effectiveness': 0.7, 'clarity': 0.72, 'consistency': 0.95, 'fav': 0.46} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages/statsmodels/stats/inter_rater.py:357: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  kappa = (agree / nobs - agree_exp) / (1 - agree_exp)\n",
      "/Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages/statsmodels/stats/inter_rater.py:372: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  var_kappa0 /= (1 - agree_exp)**2 * nobs\n",
      "/Users/roxanneelbaff/.pyenv/versions/3.11.9/lib/python3.11/site-packages/statsmodels/stats/inter_rater.py:421: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  kappa_max = (np.minimum(freq_row, freq_col).sum() - agree_exp) / \\\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from statsmodels.stats.inter_rater import aggregate_raters, fleiss_kappa, cohens_kappa, to_table\n",
    "import krippendorff\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import itertools\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau\n",
    "import pandas as pd\n",
    "\n",
    "def format_fk(ratings):\n",
    "    \n",
    "    agg = aggregate_raters(ratings, )\n",
    "\n",
    "\n",
    "    return agg, fleiss_kappa(agg, method='fleiss')\n",
    "\n",
    "# Example annotation data for a binary rating task with three annotators\n",
    "# Each row is an item, and each column is an annotator's binary decision (0 or 1)\n",
    "annotations = [\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1],\n",
    "    [0, 1, 1],\n",
    "    [0, 0, 0],\n",
    "    [1, 0, 1]\n",
    "]\n",
    "\n",
    "def get_rows_as_items_and_cols_as_raters(df, normalize = False):\n",
    "    criteria_dict = {}\n",
    "   \n",
    "    for cr in ['original_effectiveness', 'rewrite1_effectiveness', 'original_effectiveness', \n",
    "               'original_clarity', 'rewrite1_clarity', 'original_clarity',\n",
    "                'original_consistency', 'rewrite1_consistency', 'original_consistency','fav'] :\n",
    "    \n",
    "        df_ = df[[cr,\"id\", \"iteration\" ]].sort_values([\"id\", \"iteration\"])\n",
    "        def do_normalize(row):\n",
    "            if row[cr] <3:\n",
    "                row[cr] = 0\n",
    "            else: row[cr] = 1\n",
    "            return row\n",
    "        if normalize and not cr.startswith(\"fav_\"):\n",
    "            df_ = df_.apply(do_normalize, axis = 1)\n",
    "        pivot_df = df_.pivot(index='id', columns='iteration', values=cr)\n",
    "        ratings_array = pivot_df.to_numpy()\n",
    "\n",
    "        criteria_dict[cr] =  ratings_array\n",
    "    return criteria_dict\n",
    "    \n",
    "def calc_majority(r):\n",
    "    total = len(r)\n",
    "    maj = 0.0\n",
    "    for item in r:\n",
    "        is_full = 1 if len(list(set(item))) == 1 else 0\n",
    "        maj = maj + is_full\n",
    "    return maj/total\n",
    "\n",
    "def get_binary_kappa(df, normalize=False):\n",
    "    ratings_per_criteria = get_rows_as_items_and_cols_as_raters(df, normalize)\n",
    "    results = {}\n",
    "    majority= {}\n",
    "    for criteria, ratings in ratings_per_criteria.items():\n",
    "    \n",
    "        # print(f\"{criteria}: \\t {fleiss_kappa_score}\")\n",
    "\n",
    "        #results[criteria] = round(fleiss_kappa(aggregate_raters(ratings)[0],  method='fleiss'), 2)\n",
    "        # results[criteria]  = round( krippendorff.alpha(reliability_data=ratings, level_of_measurement=\"nominal\"), 2)\n",
    "        raters_pair = list(itertools.combinations(range(0, len(ratings[0])), 2))\n",
    "\n",
    "        # Assuming 'ratings' is a numpy array with rows as items and columns as raters\n",
    "        kappas = 0.0\n",
    "        pari = 0\n",
    "        for pair in raters_pair:\n",
    "\n",
    "            selected_elements = ratings[range(len(ratings)), :][:, list(pair)]\n",
    "            #assert len(selected_elements) == 2\n",
    "            kappas = kappas + cohens_kappa(to_table(selected_elements)[0]).kappa\n",
    "            pari = pari +1\n",
    "            \n",
    "        results[criteria] = kappas / pari# cohens_kappa(to_table(ratings)[0]).kappa\n",
    "\n",
    "\n",
    "        majority[criteria] = calc_majority(ratings)\n",
    "\n",
    "    results_g  = {}\n",
    "    majority_g = {}\n",
    "    ratings_per_all_models = {\"effectiveness\": [],\n",
    "                              \"clarity\": [],\n",
    "                              \"consistency\": [],\n",
    "                              \"fav\": []\n",
    "                              }\n",
    "    for crit in ['effectiveness', 'clarity', 'consistency' , \"fav\"]:\n",
    "        for criteria, ratings in ratings_per_criteria.items():\n",
    "            \n",
    "            if criteria.endswith(crit):\n",
    "                ratings_per_all_models[crit].extend(ratings)\n",
    "               \n",
    "\n",
    "    for criteria, ratings in ratings_per_all_models.items():\n",
    "        ratings = np.array(ratings)\n",
    "        raters_pair = list(itertools.combinations(range(1, len(ratings[0])), 2))\n",
    "\n",
    "        # Assuming 'ratings' is a numpy array with rows as items and columns as raters\n",
    "        kappas = 0.0\n",
    "        pari = 0\n",
    "        for pair in raters_pair:\n",
    "            \n",
    "            selected_elements = ratings[range(len(ratings)), :][:, list(pair)]\n",
    "\n",
    "            kappas = kappas + cohens_kappa(to_table(selected_elements)[0]).kappa\n",
    "            pari = pari +1\n",
    "            \n",
    "        results_g[criteria] = kappas / pari# cohens_kappa(to_table(ratings)[0]).kappa\n",
    "\n",
    "        # print(f\"{criteria}: \\t {fleiss_kappa_score}\")\n",
    "        #results_g[criteria] = cohens_kappa(to_table(ratings)[0])#round(fleiss_kappa(aggregate_raters(ratings)[0],  method='fleiss'), 2)\n",
    "        # results_g[criteria]  = round( krippendorff.alpha(reliability_data=ratings, level_of_measurement=\"nominal\"), 2)\n",
    "\n",
    "        majority_g[criteria] = calc_majority(ratings)\n",
    "\n",
    "    return results, majority, ratings, results_g, majority_g\n",
    "\n",
    "for kk in dfssss.keys():\n",
    "    kappa, majority, r, results_g, majority_g = get_binary_kappa(dfssss[kk]\n",
    "                                                                , True)\n",
    "    print(f\"{kk} KAPPA:{results_g}, FULL:{majority_g} \")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>batch</th>\n",
       "      <th>favorite</th>\n",
       "      <th>rewrite1_effectiveness</th>\n",
       "      <th>rewrite2_clarity</th>\n",
       "      <th>rewrite2_feedback</th>\n",
       "      <th>ideology</th>\n",
       "      <th>prompt</th>\n",
       "      <th>original_feedback</th>\n",
       "      <th>id</th>\n",
       "      <th>rewrite2_consistency</th>\n",
       "      <th>original_consistency</th>\n",
       "      <th>rewrite1_consistency</th>\n",
       "      <th>rewrite2_effectiveness</th>\n",
       "      <th>original_effectiveness</th>\n",
       "      <th>rewrite1_clarity</th>\n",
       "      <th>original_clarity</th>\n",
       "      <th>rewrite1_feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "      <td>rewrite2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>the rewritten argument is clear and structured...</td>\n",
       "      <td>Flag and Faith Conservative ideology</td>\n",
       "      <td>Human: From now on, you are an American with a...</td>\n",
       "      <td>the original argument is not clear and lacks s...</td>\n",
       "      <td>50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>the rewritten argument is clearer and more str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "      <td>rewrite1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>rewrite 2 is similar to the original argument ...</td>\n",
       "      <td>Flag and Faith Conservative ideology</td>\n",
       "      <td>Human: From now on, you are an American with a...</td>\n",
       "      <td>the original argument is somewhat effective in...</td>\n",
       "      <td>51</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>rewrite 1 is clear and concise, effectively co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "      <td>rewrite2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>this argument is clear and to the point. it ef...</td>\n",
       "      <td>Flag and Faith Conservative ideology</td>\n",
       "      <td>Human: From now on, you are an American with a...</td>\n",
       "      <td>the original argument is ineffective as it lac...</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>this argument is clear and structured, but it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "      <td>rewrite1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>rewrite 2 is clear, consistent, and effectivel...</td>\n",
       "      <td>Flag and Faith Conservative ideology</td>\n",
       "      <td>Human: From now on, you are an American with a...</td>\n",
       "      <td>the original argument is somewhat effective in...</td>\n",
       "      <td>53</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>rewrite 1 is clear, consistent, and presents t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "      <td>rewrite1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Rewrite 2 is consistent with the original argu...</td>\n",
       "      <td>Flag and Faith Conservative ideology</td>\n",
       "      <td>Human: From now on, you are an American with a...</td>\n",
       "      <td>The original argument effectively breaks down ...</td>\n",
       "      <td>54</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Rewrite 1 captures the original argument's mai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>5</td>\n",
       "      <td>conservative</td>\n",
       "      <td>original</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>this rewrite is a more formal version of the o...</td>\n",
       "      <td>Flag and Faith Conservative ideology</td>\n",
       "      <td>Human: From now on, you are an American with a...</td>\n",
       "      <td>the original argument is a simple statement ac...</td>\n",
       "      <td>95</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>the rewrite is similar in meaning to the origi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>5</td>\n",
       "      <td>conservative</td>\n",
       "      <td>rewrite2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>the rewrite is fully effective in presenting t...</td>\n",
       "      <td>Flag and Faith Conservative ideology</td>\n",
       "      <td>Human: From now on, you are an American with a...</td>\n",
       "      <td>the original argument is fairly effective in p...</td>\n",
       "      <td>96</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>the rewrite is mostly effective in presenting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>5</td>\n",
       "      <td>conservative</td>\n",
       "      <td>original</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>the rewrite argues that planets are indeed isl...</td>\n",
       "      <td>Flag and Faith Conservative ideology</td>\n",
       "      <td>Human: From now on, you are an American with a...</td>\n",
       "      <td>the original argument clearly lays out the def...</td>\n",
       "      <td>97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>the rewrite argues that planets are not island...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>5</td>\n",
       "      <td>conservative</td>\n",
       "      <td>rewrite2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>rewrite 2 is clear, well-structured, and more ...</td>\n",
       "      <td>Flag and Faith Conservative ideology</td>\n",
       "      <td>Human: From now on, you are an American with a...</td>\n",
       "      <td>the original argument is somewhat effective du...</td>\n",
       "      <td>98</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>rewrite 1 is clearer and more structured than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>5</td>\n",
       "      <td>conservative</td>\n",
       "      <td>original</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>rewrite 2 is very similar to the original argu...</td>\n",
       "      <td>Flag and Faith Conservative ideology</td>\n",
       "      <td>Human: From now on, you are an American with a...</td>\n",
       "      <td>the original argument is generally clear and e...</td>\n",
       "      <td>99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>rewrite 1 clarifies some sentences and improve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iteration         batch  favorite  rewrite1_effectiveness  \\\n",
       "0            1  conservative  rewrite2                     2.0   \n",
       "1            1  conservative  rewrite1                     4.0   \n",
       "2            1  conservative  rewrite2                     1.0   \n",
       "3            1  conservative  rewrite1                     4.0   \n",
       "4            1  conservative  rewrite1                     4.0   \n",
       "..         ...           ...       ...                     ...   \n",
       "245          5  conservative  original                     3.0   \n",
       "246          5  conservative  rewrite2                     4.0   \n",
       "247          5  conservative  original                     4.0   \n",
       "248          5  conservative  rewrite2                     3.0   \n",
       "249          5  conservative  original                     3.0   \n",
       "\n",
       "     rewrite2_clarity                                  rewrite2_feedback  \\\n",
       "0                 5.0  the rewritten argument is clear and structured...   \n",
       "1                 4.0  rewrite 2 is similar to the original argument ...   \n",
       "2                 5.0  this argument is clear and to the point. it ef...   \n",
       "3                 5.0  rewrite 2 is clear, consistent, and effectivel...   \n",
       "4                 3.0  Rewrite 2 is consistent with the original argu...   \n",
       "..                ...                                                ...   \n",
       "245               5.0  this rewrite is a more formal version of the o...   \n",
       "246               5.0  the rewrite is fully effective in presenting t...   \n",
       "247               5.0  the rewrite argues that planets are indeed isl...   \n",
       "248               5.0  rewrite 2 is clear, well-structured, and more ...   \n",
       "249               4.0  rewrite 2 is very similar to the original argu...   \n",
       "\n",
       "                                 ideology  \\\n",
       "0    Flag and Faith Conservative ideology   \n",
       "1    Flag and Faith Conservative ideology   \n",
       "2    Flag and Faith Conservative ideology   \n",
       "3    Flag and Faith Conservative ideology   \n",
       "4    Flag and Faith Conservative ideology   \n",
       "..                                    ...   \n",
       "245  Flag and Faith Conservative ideology   \n",
       "246  Flag and Faith Conservative ideology   \n",
       "247  Flag and Faith Conservative ideology   \n",
       "248  Flag and Faith Conservative ideology   \n",
       "249  Flag and Faith Conservative ideology   \n",
       "\n",
       "                                                prompt  \\\n",
       "0    Human: From now on, you are an American with a...   \n",
       "1    Human: From now on, you are an American with a...   \n",
       "2    Human: From now on, you are an American with a...   \n",
       "3    Human: From now on, you are an American with a...   \n",
       "4    Human: From now on, you are an American with a...   \n",
       "..                                                 ...   \n",
       "245  Human: From now on, you are an American with a...   \n",
       "246  Human: From now on, you are an American with a...   \n",
       "247  Human: From now on, you are an American with a...   \n",
       "248  Human: From now on, you are an American with a...   \n",
       "249  Human: From now on, you are an American with a...   \n",
       "\n",
       "                                     original_feedback  id  \\\n",
       "0    the original argument is not clear and lacks s...  50   \n",
       "1    the original argument is somewhat effective in...  51   \n",
       "2    the original argument is ineffective as it lac...  52   \n",
       "3    the original argument is somewhat effective in...  53   \n",
       "4    The original argument effectively breaks down ...  54   \n",
       "..                                                 ...  ..   \n",
       "245  the original argument is a simple statement ac...  95   \n",
       "246  the original argument is fairly effective in p...  96   \n",
       "247  the original argument clearly lays out the def...  97   \n",
       "248  the original argument is somewhat effective du...  98   \n",
       "249  the original argument is generally clear and e...  99   \n",
       "\n",
       "     rewrite2_consistency  original_consistency  rewrite1_consistency  \\\n",
       "0                     3.0                   5.0                   5.0   \n",
       "1                     5.0                   5.0                   5.0   \n",
       "2                     3.0                   5.0                   1.0   \n",
       "3                     5.0                   5.0                   5.0   \n",
       "4                     5.0                   5.0                   5.0   \n",
       "..                    ...                   ...                   ...   \n",
       "245                   5.0                   5.0                   5.0   \n",
       "246                   5.0                   NaN                   3.0   \n",
       "247                   1.0                   5.0                   2.0   \n",
       "248                   5.0                   5.0                   5.0   \n",
       "249                   5.0                   5.0                   2.0   \n",
       "\n",
       "     rewrite2_effectiveness  original_effectiveness  rewrite1_clarity  \\\n",
       "0                       3.0                     2.0               4.0   \n",
       "1                       4.0                     3.0               5.0   \n",
       "2                       2.0                     1.0               5.0   \n",
       "3                       4.0                     3.0               5.0   \n",
       "4                       4.0                     4.0               5.0   \n",
       "..                      ...                     ...               ...   \n",
       "245                     3.0                     3.0               5.0   \n",
       "246                     5.0                     3.0               5.0   \n",
       "247                     2.0                     3.0               5.0   \n",
       "248                     4.0                     3.0               4.0   \n",
       "249                     4.0                     4.0               5.0   \n",
       "\n",
       "     original_clarity                                  rewrite1_feedback  \n",
       "0                 2.0  the rewritten argument is clearer and more str...  \n",
       "1                 3.0  rewrite 1 is clear and concise, effectively co...  \n",
       "2                 3.0  this argument is clear and structured, but it ...  \n",
       "3                 3.0  rewrite 1 is clear, consistent, and presents t...  \n",
       "4                 3.0  Rewrite 1 captures the original argument's mai...  \n",
       "..                ...                                                ...  \n",
       "245               5.0  the rewrite is similar in meaning to the origi...  \n",
       "246               4.0  the rewrite is mostly effective in presenting ...  \n",
       "247               5.0  the rewrite argues that planets are not island...  \n",
       "248               3.0  rewrite 1 is clearer and more structured than ...  \n",
       "249               4.0  rewrite 1 clarifies some sentences and improve...  \n",
       "\n",
       "[250 rows x 18 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfssss[\"Mixtral8x7B_Conservative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>effectiveness_rewrite1</th>\n",
       "      <th>model</th>\n",
       "      <th>ideology</th>\n",
       "      <th>iteration</th>\n",
       "      <th>id</th>\n",
       "      <th>effectiveness_rewrite2</th>\n",
       "      <th>effectiveness_original</th>\n",
       "      <th>clarity_rewrite2</th>\n",
       "      <th>clarity_rewrite1</th>\n",
       "      <th>clarity_original</th>\n",
       "      <th>consistency_rewrite2</th>\n",
       "      <th>consistency_original</th>\n",
       "      <th>consistency_rewrite1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Mixtral8x7B</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mixtral8x7B</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mixtral8x7B</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Mixtral8x7B</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mixtral8x7B</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   effectiveness_rewrite1        model      ideology  iteration  id  \\\n",
       "0                     2.0  Mixtral8x7B  Conservative          1  50   \n",
       "1                     NaN  Mixtral8x7B  Conservative          1  50   \n",
       "2                     NaN  Mixtral8x7B  Conservative          1  50   \n",
       "3                     4.0  Mixtral8x7B  Conservative          1  51   \n",
       "4                     NaN  Mixtral8x7B  Conservative          1  51   \n",
       "\n",
       "   effectiveness_rewrite2  effectiveness_original  clarity_rewrite2  \\\n",
       "0                     NaN                     NaN               NaN   \n",
       "1                     3.0                     NaN               NaN   \n",
       "2                     NaN                     2.0               NaN   \n",
       "3                     NaN                     NaN               NaN   \n",
       "4                     4.0                     NaN               NaN   \n",
       "\n",
       "   clarity_rewrite1  clarity_original  consistency_rewrite2  \\\n",
       "0               NaN               NaN                   NaN   \n",
       "1               NaN               NaN                   NaN   \n",
       "2               NaN               NaN                   NaN   \n",
       "3               NaN               NaN                   NaN   \n",
       "4               NaN               NaN                   NaN   \n",
       "\n",
       "   consistency_original  consistency_rewrite1  \n",
       "0                   NaN                   NaN  \n",
       "1                   NaN                   NaN  \n",
       "2                   NaN                   NaN  \n",
       "3                   NaN                   NaN  \n",
       "4                   NaN                   NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_llm_based_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data/llms_out/llm_evaluation/conservative_mixtral_processed.csv\n",
      "Mixtral8x7B_Conservative\n",
      "processing data/llms_out/llm_evaluation/liberal_mixtral_processed.csv\n",
      "Mixtral8x7B_Liberal\n",
      "processing data/llms_out/llm_evaluation/liberal_gpt-4.jsonl\n",
      "GPT4_Liberal\n",
      "processing data/llms_out/llm_evaluation/conservative_gpt-4_based_eval1-5.jsonl\n",
      "GPT4_Conservative\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "eval_files = glob(\"data/llms_out/llm_evaluation/*.*\")\n",
    "criterion = [\"effectiveness\", \"clarity\", \"consistency\", \"favorite\"]\n",
    "#all_eval_per_criteria = {k:[] for k in criterion}\n",
    "all_llm_eval = []\n",
    "model = \"GPT4\"\n",
    "\n",
    "dfssss ={}\n",
    "for file in eval_files:\n",
    "    print(f\"processing {file}\")\n",
    "    \n",
    "    if file.endswith(\"csv\"):\n",
    "        df_ = pd.read_csv(file)\n",
    "    else: \n",
    "        df_ = pd.read_json(file, lines=True)\n",
    "    def _appp (row):\n",
    "        if row[\"favorite\"] == \"rewrite1\":\n",
    "            row[\"fav\"] = 2\n",
    "        elif row[\"favorite\"] == \"rewrite2\":\n",
    "            row[\"fav\"] = 3\n",
    "        else:\n",
    "            row[\"fav\"] = 1\n",
    "        return row\n",
    "    \n",
    "\n",
    "    df_ = df_[df_[\"iteration\"].isin(range(1,6))].apply(_appp, axis=1)\n",
    "  \n",
    "\n",
    "    model_name_ = \"GPT4\" if file.find(\"gpt-4\")>-1 else \"Mixtral8x7B\"\n",
    "    ideology =  \"Liberal\" if file.find(\"liberal\")>-1 else \"Conservative\"\n",
    "    dfssss[f\"{model_name_}_{ideology}\"] = df_\n",
    "    print(f\"{model_name_}_{ideology}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ineffective effectiveness : 48.7\\%(12.7\\%)\n",
      "\t mean: 2.49 \t 0.87 \n",
      "\n",
      "llama2 effectiveness : 88.0\\%(41.3\\%)\n",
      "\t mean: 3.32 \t 0.8 \n",
      "\n",
      "chatgpt effectiveness : 88.7\\%(56.7\\%)\n",
      "\t mean: 3.51 \t 0.84 \n",
      "\n",
      "ineffective clarity : 58.7\\%(24.7\\%)\n",
      "\t mean: 2.79 \t 1.0 \n",
      "\n",
      "llama2 clarity : 91.3\\%(56.7\\%)\n",
      "\t mean: 3.53 \t 0.78 \n",
      "\n",
      "chatgpt clarity : 95.3\\%(65.3\\%)\n",
      "\t mean: 3.68 \t 0.71 \n",
      "\n",
      "llama2 consistency : 63.3\\%(40.0\\%)\n",
      "\t mean: 2.97 \t 1.23 \n",
      "\n",
      "chatgpt consistency : 90.7\\%(67.3\\%)\n",
      "\t mean: 3.8 \t 0.96 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_stat(df):\n",
    "    model_dict = {1: \"ineffective\", 2: \"llama2\", 3: \"chatgpt\"}\n",
    "    for scoret in [f\"effectiveness\", f\"clarity\", f\"consistency\"]:\n",
    "        for n in range(1,4):\n",
    "            col = f\"{scoret}_arg{n}\"\n",
    "            if col == \"consistency_arg1\":\n",
    "                continue\n",
    "            print(f\"{model_dict[n]} {scoret} : {round(len(df[df[f'is_{col}']])/len(df)*100, 1)}\\%\"\n",
    "                  f\"({round(len(df[df[f'is_highly_{col}']])/len(df)*100, 1)}\\%)\")\n",
    "\n",
    "            print(f\"\\t mean: {round(df[f'{col}'].mean(),2)} \\t {round(df[f'{col}'].std(),2)} \\n\")\n",
    "print_stat(liberal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.50\n",
       "2    0.42\n",
       "1    0.08\n",
       "Name: favorite, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liberal[\"favorite\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative = human_evaluation[human_evaluation[\"user_id\"].isin(conservative_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ineffective effectiveness : 32.2\\%(8.9\\%)\n",
      "\t mean: 2.2 \t 0.91 \n",
      "\n",
      "llama2 effectiveness : 93.3\\%(68.9\\%)\n",
      "\t mean: 3.69 \t 0.79 \n",
      "\n",
      "chatgpt effectiveness : 78.9\\%(52.2\\%)\n",
      "\t mean: 3.36 \t 1.04 \n",
      "\n",
      "ineffective clarity : 38.9\\%(11.1\\%)\n",
      "\t mean: 2.31 \t 0.91 \n",
      "\n",
      "llama2 clarity : 93.3\\%(68.9\\%)\n",
      "\t mean: 3.7 \t 0.71 \n",
      "\n",
      "chatgpt clarity : 84.4\\%(53.3\\%)\n",
      "\t mean: 3.43 \t 0.86 \n",
      "\n",
      "llama2 consistency : 96.7\\%(64.4\\%)\n",
      "\t mean: 3.66 \t 0.62 \n",
      "\n",
      "chatgpt consistency : 86.7\\%(46.7\\%)\n",
      "\t mean: 3.38 \t 0.82 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_stat(conservative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.577778\n",
       "3    0.388889\n",
       "1    0.033333\n",
       "Name: favorite, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conservative[\"favorite\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
