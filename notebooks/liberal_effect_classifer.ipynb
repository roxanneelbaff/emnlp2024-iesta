{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  iesta.machine_learning.dataloader import load_features_df\n",
    "import iesta.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, feature_dfs = load_features_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberal_training = feature_dfs['liberal']\n",
    "liberal_training = liberal_training[liberal_training[\"effect\"]!=\"okay\"]\n",
    "liberal_training.effect.unique()\n",
    "liberal_training[\"binary_effect\"].value_counts()\n",
    "unique_debates = liberal_training.debate_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "training_debates, testval_debates = train_test_split(unique_debates, test_size=0.3,\n",
    "                 random_state=42,\n",
    "                 shuffle=True)\n",
    "\n",
    "def _add_splits(row, training_debates, testval_debates):\n",
    "    if row['debate_id'] in training_debates:\n",
    "        row[\"classifier_split\"] = \"train\"\n",
    "    elif row['debate_id'] in testval_debates:\n",
    "        row[\"classifier_split\"] = \"test\"\n",
    "    else:\n",
    "        assert False\n",
    "    return row \n",
    "\n",
    "liberal_training = liberal_training.apply(_add_splits, args=(training_debates,testval_debates, ),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberal_training.classifier_split.value_counts()\n",
    "\n",
    "pd.crosstab(liberal_training.classifier_split, liberal_training.binary_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "def filter_cols(cols):\n",
    "    prefices = [\"mpqa\", \"hedge\", \"emotion\", \"toxicity\", \"mpqa\", \"empath\"]\n",
    "    keep = [c for c in cols if c.split(\"_\")[0] in prefices and not c.endswith(\"_count\")]\n",
    "    return keep\n",
    "\n",
    "def filter_feature_df(df: pd.DataFrame, class_col: str = \"effect\", split_col: str = \"classifier_split\") : # binary_effect\n",
    "    feature_cols = filter_cols(df.columns.tolist())\n",
    "    df_ = df[feature_cols+[class_col, split_col]].copy()\n",
    "    numeric_cols = df_.select_dtypes(include=np.number).columns.tolist()\n",
    "    df_ = df_[numeric_cols+[class_col, split_col]]\n",
    "    \n",
    "    df_.fillna(0.0, inplace=True)\n",
    "    #X = df_.values\n",
    "    #y_str = df[class_].values\n",
    "\n",
    "\n",
    "    #def to_numeric(x):\n",
    "    #    return 0 if x == \"ineffective\" else (1 if x == \"effective\" else 2)\n",
    "    #y = [to_numeric(x) for x in y_str]\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "_df = filter_feature_df(liberal_training, class_col = \"binary_effect\", split_col = \"classifier_split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.binary_effect.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U nlpaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpaf.ml.feature_based import FeatureBasedML\n",
    "\n",
    "trainer = FeatureBasedML(y_col=\"binary_effect\", dataset=_df, split_label_name=\"classification_split\", remove_outliers=False, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = trainer.train_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfold_results = trainer.train_xfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iesta_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
