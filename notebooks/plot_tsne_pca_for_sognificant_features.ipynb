{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e8a38a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elba_ro/repos/conf22-style-transfer/iesta_venv/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys, os, importlib\n",
    "\n",
    "\n",
    "import iesta.loader\n",
    "import iesta.processor as processor\n",
    "import iesta.properties as prop\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sns.reset_defaults()\n",
    "sns.set(\n",
    "    rc={\"figure.figsize\": (6, 4)},\n",
    "    # style=\"white\" # nicer layout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eccb1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "\n",
    "# PREPARE DATA FOR pca\n",
    "\n",
    "\n",
    "#X_norm = (X - X.min())/(X.max() - X.min())\n",
    "#X_standardized = StandardScaler().fit_transform(X)\n",
    "def plot_pca(original_df:pd.DataFrame, title:str, hue:str ):\n",
    "    df = original_df.fillna(0).copy()\n",
    "    print(f\"{len(df.columns.tolist())} columns\")\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    num_cols = df.select_dtypes(include=numerics).columns.to_list()\n",
    "    if \"round\" in num_cols:\n",
    "        num_cols.remove(\"round\")\n",
    "        print(\"removing round\")\n",
    "    cols = num_cols + [hue]\n",
    "\n",
    "    print(f\"{len(cols)} columns\")\n",
    "\n",
    "    X=df.loc[:,num_cols].values  \n",
    "    X.fill\n",
    "    y=df.loc[:,hue].values\n",
    "    #Apply Standard Scaling\n",
    "    sc=StandardScaler()  \n",
    "    X=sc.fit_transform(X) \n",
    "    #pd.DataFrame(X,columns=feature).head()\n",
    "    #Define two components  \n",
    "    pca=PCA(n_components=2) \n",
    "    principalComponents=pca.fit_transform(X) \n",
    "    principalDf=pd.DataFrame(data=principalComponents,columns=['principal component 1','principal component 2']) \n",
    "    #principalDf.head()\n",
    "    finalDf=pd.concat([principalDf,df[[hue]]],axis=1)\n",
    "    \n",
    "    fig=plt.figure(figsize=(8,8))  \n",
    "    ax=fig.add_subplot(1,1,1)  \n",
    "    ax.set_xlabel('Principal Component 1',fontsize = 15)  \n",
    "    ax.set_ylabel('Principal Component 2',fontsize = 15)  \n",
    "    ax.set_title(title,fontsize=20)  \n",
    "    targets=list(df[hue].unique())\n",
    "    colors= ['b', 'g', 'y', 'm']#sns.color_palette('deep')[:len(targets)]\n",
    "    for target,color in zip(targets,colors):    \n",
    "        indicesToKeep = finalDf[hue] == target  \n",
    "        ax.scatter(finalDf.loc[indicesToKeep,'principal component 1'],\n",
    "                  finalDf.loc[indicesToKeep,'principal component 2'],\n",
    "                 c=color,\n",
    "                 s=50)\n",
    "        ax.xaxis.label.set_color('white')\n",
    "        ax.yaxis.label.set_color('white')\n",
    "        ax.title.set_color('white')\n",
    "        ax.tick_params(axis='x', colors='white')\n",
    "        ax.tick_params(axis='y', colors='white')\n",
    "        ax.legend(targets)  \n",
    "        ax.grid()\n",
    "    plt.figure(figsize=(10,7))\n",
    "    \n",
    "    sns.scatterplot(\n",
    "        x=\"principal component 1\", y=\"principal component 2\",\n",
    "        hue=hue,\n",
    "        palette=sns.color_palette(\"hls\", 4),\n",
    "        data=finalDf.loc[indicesToKeep, :],\n",
    "        legend=\"full\",\n",
    "        alpha=0.3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3218574f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elba_ro/repos/conf22-style-transfer/iesta/../data/splitted_conservative_debate_arguments_effect_test0.3_random2.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iesta        INFO     File already created. Loading file...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elba_ro/repos/conf22-style-transfer/iesta/../data/splitted_liberal_debate_arguments_effect_test0.3_random2.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iesta        INFO     File already created. Loading file...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316: ../data/extracted_features//conservative_style-features_1000/conservative_batch1000_72_style-features.parquet\n",
      "16: ../data/extracted_features//conservative_transformer-features_100/conservative_batch100_714_transformer-features.parquet\n",
      "792: ../data/extracted_features//liberal_style-features_1000/liberal_batch1000_47_style-features.parquet\n",
      "92: ../data/extracted_features//liberal_transformer-features_100/liberal_batch100_468_transformer-features.parquet\n"
     ]
    }
   ],
   "source": [
    "from iesta.machine_learning import dataloader\n",
    "from iesta.stats import significance\n",
    "\n",
    "training_df, feature_dfs = dataloader.load_features_df()\n",
    "significance_results = significance.run_all_significance_test(feature_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "411b9fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['conservative_effect_undersampled_all_features', 'conservative_effect_all_features', 'conservative_effect_undersampled_Okay_all_features', 'conservative_effect_Okay_all_features', 'conservative_binary_effect_undersampled_all_features', 'conservative_binary_effect_all_features', 'conservative_binary_effect_undersampled_Okay_all_features', 'conservative_binary_effect_Okay_all_features', 'liberal_effect_undersampled_all_features', 'liberal_effect_all_features', 'liberal_effect_undersampled_Okay_all_features', 'liberal_effect_Okay_all_features', 'liberal_binary_effect_undersampled_all_features', 'liberal_binary_effect_all_features', 'liberal_binary_effect_undersampled_Okay_all_features', 'liberal_binary_effect_Okay_all_features'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significance_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28e483cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_df(ideology, cols):\n",
    "    return feature_dfs[ideology][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3efcb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 columns\n",
      "28 columns\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m cols \u001b[39m=\u001b[39m significance_results[key][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      3\u001b[0m cols\n\u001b[0;32m----> 4\u001b[0m plot_pca(get_filtered_df(\u001b[39m\"\u001b[39;49m\u001b[39mconservative\u001b[39;49m\u001b[39m\"\u001b[39;49m, cols\u001b[39m+\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mbinary_effect\u001b[39;49m\u001b[39m\"\u001b[39;49m] ), title \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mconservative\u001b[39;49m\u001b[39m\"\u001b[39;49m, hue\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbinary_effect\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [20], line 33\u001b[0m, in \u001b[0;36mplot_pca\u001b[0;34m(df, title, hue)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39m#pd.DataFrame(X,columns=feature).head()\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m#Define two components  \u001b[39;00m\n\u001b[1;32m     32\u001b[0m pca\u001b[39m=\u001b[39mPCA(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m) \n\u001b[0;32m---> 33\u001b[0m principalComponents\u001b[39m=\u001b[39mpca\u001b[39m.\u001b[39;49mfit_transform(X) \n\u001b[1;32m     34\u001b[0m principalDf\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39mprincipalComponents,columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mprincipal component 1\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mprincipal component 2\u001b[39m\u001b[39m'\u001b[39m]) \n\u001b[1;32m     35\u001b[0m \u001b[39m#principalDf.head()\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/conf22-style-transfer/iesta_venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:433\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    412\u001b[0m     \u001b[39m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \n\u001b[1;32m    414\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     U, S, Vt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[1;32m    434\u001b[0m     U \u001b[39m=\u001b[39m U[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components_]\n\u001b[1;32m    436\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhiten:\n\u001b[1;32m    437\u001b[0m         \u001b[39m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/conf22-style-transfer/iesta_venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:456\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[1;32m    451\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPCA does not support sparse input. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTruncatedSVD for a possible alternative.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m     )\n\u001b[0;32m--> 456\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    457\u001b[0m     X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[1;32m    458\u001b[0m )\n\u001b[1;32m    460\u001b[0m \u001b[39m# Handle n_components==None\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/repos/conf22-style-transfer/iesta_venv/lib/python3.8/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/repos/conf22-style-transfer/iesta_venv/lib/python3.8/site-packages/sklearn/utils/validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[1;32m    900\u001b[0m             array,\n\u001b[1;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    904\u001b[0m         )\n\u001b[1;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/repos/conf22-style-transfer/iesta_venv/lib/python3.8/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "key = \"conservative_binary_effect_undersampled_all_features\"\n",
    "cols = significance_results[key][0].index.tolist()\n",
    "cols\n",
    "plot_pca(\n",
    "    get_filtered_df(\"conservative\", cols + [\"binary_effect\"]),\n",
    "    title=\"conservative\",\n",
    "    hue=\"binary_effect\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb360003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "854 columns\n",
      "removing round\n",
      "446 columns\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m cols\n\u001b[1;32m      4\u001b[0m \u001b[39m#plot_pca(get_filtered_df(\"liberal\", cols+[\"binary_effect\"] ), title = \"Liberal\", hue=\"binary_effect\")\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m plot_pca(feature_dfs[\u001b[39m\"\u001b[39;49m\u001b[39mliberal\u001b[39;49m\u001b[39m\"\u001b[39;49m], title \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mLiberal\u001b[39;49m\u001b[39m\"\u001b[39;49m, hue\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbinary_effect\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [20], line 33\u001b[0m, in \u001b[0;36mplot_pca\u001b[0;34m(df, title, hue)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39m#pd.DataFrame(X,columns=feature).head()\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m#Define two components  \u001b[39;00m\n\u001b[1;32m     32\u001b[0m pca\u001b[39m=\u001b[39mPCA(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m) \n\u001b[0;32m---> 33\u001b[0m principalComponents\u001b[39m=\u001b[39mpca\u001b[39m.\u001b[39;49mfit_transform(X) \n\u001b[1;32m     34\u001b[0m principalDf\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39mprincipalComponents,columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mprincipal component 1\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mprincipal component 2\u001b[39m\u001b[39m'\u001b[39m]) \n\u001b[1;32m     35\u001b[0m \u001b[39m#principalDf.head()\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/conf22-style-transfer/iesta_venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:433\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    412\u001b[0m     \u001b[39m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \n\u001b[1;32m    414\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     U, S, Vt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[1;32m    434\u001b[0m     U \u001b[39m=\u001b[39m U[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components_]\n\u001b[1;32m    436\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhiten:\n\u001b[1;32m    437\u001b[0m         \u001b[39m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/conf22-style-transfer/iesta_venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:456\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[1;32m    451\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPCA does not support sparse input. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTruncatedSVD for a possible alternative.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m     )\n\u001b[0;32m--> 456\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    457\u001b[0m     X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[1;32m    458\u001b[0m )\n\u001b[1;32m    460\u001b[0m \u001b[39m# Handle n_components==None\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/repos/conf22-style-transfer/iesta_venv/lib/python3.8/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/repos/conf22-style-transfer/iesta_venv/lib/python3.8/site-packages/sklearn/utils/validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[1;32m    900\u001b[0m             array,\n\u001b[1;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    904\u001b[0m         )\n\u001b[1;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/repos/conf22-style-transfer/iesta_venv/lib/python3.8/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "key = \"liberal_binary_effect_all_features\"\n",
    "cols = significance_results[key][0].index.tolist()\n",
    "cols\n",
    "# plot_pca(get_filtered_df(\"liberal\", cols+[\"binary_effect\"] ), title = \"Liberal\", hue=\"binary_effect\")\n",
    "\n",
    "plot_pca(feature_dfs[\"liberal\"], title=\"Liberal\", hue=\"binary_effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611e974c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iesta_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "33b81bc8650a3643e935a2ab53ff66219719f7237086cfdf4850911b872414e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
