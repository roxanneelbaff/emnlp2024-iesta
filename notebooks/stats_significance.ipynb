{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show iesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dotenv was True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elba_ro/repos/github/conf22-style-transfer/.venv/lib/python3.9/site-packages/numba/core/decorators.py:262: NumbaDeprecationWarning: numba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\n",
      "  warnings.warn(msg, NumbaDeprecationWarning)\n",
      "/home/elba_ro/repos/github/conf22-style-transfer/.venv/lib/python3.9/site-packages/visions/backends/shared/nan_handling.py:51: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def hasna(x: np.ndarray) -> bool:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import iesta.machine_learning.dataloader\n",
    "#from .autonotebook import tqdm as notebook_tqdm\n",
    "import iesta.stats.significance\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sns.reset_defaults()\n",
    "\n",
    "sns.set(\n",
    "    rc={'figure.figsize':(3,2)}, \n",
    "    #style=\"white\" # nicer layout\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Significance tests on Training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#significance[_key][0]\n",
    "\n",
    "\n",
    "def filter_significance(significance_report,\n",
    "                        col_name,\n",
    "                        threshold: int = 0.00):\n",
    "    def _apply_absolute_effect(row):\n",
    "        effect = row[col_name] \n",
    "        row['absolute_effect'] = effect*(-1) if effect < 0.0 else effect\n",
    "        return row\n",
    "    _df : pd.DataFrame = significance_report.reset_index().copy()\n",
    "    _df = _df[\n",
    "        (~_df[\"feature\"].str.endswith(\"_count\")) & \n",
    "        (~_df[\"feature\"].str.startswith(\"empath\"))\n",
    "\n",
    "    ]\n",
    "\n",
    "\n",
    "    if \"Unnamed: 0\" in _df.columns.tolist():\n",
    "        del _df[\"Unnamed: 0\"]\n",
    "    _df = _df.apply(_apply_absolute_effect, axis=1)\n",
    "    _df = _df.sort_values(by=['absolute_effect'], ascending=False)\n",
    "    _df = _df[_df['absolute_effect']>=threshold] if threshold>0.0 else _df\n",
    "    _df.set_index(\"feature\", inplace=True)\n",
    "\n",
    "    return _df\n",
    "\n",
    "import iesta.properties as prop\n",
    "\n",
    "def calculate_filter_join_ideologies():\n",
    "    ## GET DATA\n",
    "    print(\"1/4 Getting data...\")\n",
    "    feature_dfs= {}\n",
    "    _, liberal_df = iesta.machine_learning.dataloader.load_training_features_df(\"Liberal\")\n",
    "    feature_dfs[\"liberal\"] = liberal_df\n",
    "\n",
    "    _, conservative_df = iesta.machine_learning.dataloader.load_training_features_df(\"Conservative\")\n",
    "    feature_dfs[\"conservative\"] = conservative_df\n",
    "\n",
    "    ## CALCULATE SIGNIFICANCE\n",
    "    print(\"2/4 Getting data...\")\n",
    "    significance_dict = iesta.stats.significance.run_all_significance_test(feature_dfs)\n",
    "\n",
    "    # Filter Results based on the EFFECT Threshold\n",
    "    print(\"3/4 Filtering data based in effect threshold...\")\n",
    "\n",
    "\n",
    "    # JOIN Results for LIBERAL AND CONSERVATIVE\n",
    "    print(\"4/4 and Joining ideologies\")\n",
    "    joined_sign_dict = {}\n",
    "    keys = [x for x in significance_dict.keys() if x.startswith(\"liberal\")]\n",
    "    for k in keys:\n",
    "        joint_sign = pd.DataFrame()\n",
    "        print(k)\n",
    "        based_key = \"_\".join(k.split(\"_\")[1:])\n",
    "        print(based_key)\n",
    "        liberal_df = significance_dict[f\"liberal_{based_key}\"][0].copy()\n",
    "        conservative_df = significance_dict[f\"conservative_{based_key}\"][0].copy()\n",
    "        col_name = [x for x in liberal_df.columns if \"effective\" in x][0]\n",
    "\n",
    "        liberal_sign_df =  filter_significance(liberal_df, col_name, threshold=0.001)\n",
    "        conservative_sign_df =  filter_significance(conservative_df, col_name, threshold=0.001)\n",
    "\n",
    "        joint_sign = liberal_sign_df.join(conservative_sign_df, how='outer', lsuffix=\"_liberal\", rsuffix=\"_conservative\")\n",
    "\n",
    "        def _apply_ideology_effect(row):\n",
    "            is_liberal =  not pd.isna(float(row['absolute_effect_liberal'])) \n",
    "            is_cons =  not pd.isna(float(row['absolute_effect_conservative'])) \n",
    "\n",
    "            if is_liberal and is_cons:\n",
    "                if row[f'{col_name}_liberal'] *  row[f'{col_name}_conservative'] > 0.0:\n",
    "                    row['label'] = 'same'\n",
    "                else: row['label'] = 'opposite'\n",
    "            else: \n",
    "                row['label'] = 'conservative' if pd.isna(float(row['absolute_effect_liberal'])) else 'liberal'\n",
    "            return row\n",
    "\n",
    "        def _add_feature_type(row):\n",
    "            row['feature_type'] = row.name.split(\"_\")[0]\n",
    "            return row\n",
    "        joint_sign = joint_sign.apply(_apply_ideology_effect, axis = 1)\n",
    "        joint_sign = joint_sign.sort_values(by=[\"label\", \"absolute_effect_conservative\", \"absolute_effect_liberal\"])\n",
    "        joint_sign = joint_sign.apply(_add_feature_type, axis= 1)\n",
    "        joined_sign_dict[based_key] = joint_sign\n",
    "        joint_sign.to_csv(f\"../data/significant_test/summary_training_{based_key}.csv\")\n",
    "    return joined_sign_dict\n",
    "\n",
    "#significance[k][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_results = calculate_filter_join_ideologies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = significance_results[\"effect\"]\n",
    "cross_df = pd.crosstab(df[ \"label\"], df[\"feature_type\"])\n",
    "cross_df['Total'] = cross_df.sum(axis=1)\n",
    "cross_df.loc['Total']= cross_df.sum()\n",
    "cross_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"effective ineffective_conservative\"], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN Dim-Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>effective ineffective_conservative</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>hedge_I_ratio</td>\n",
       "      <td>0.09</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>hedge_E_ratio</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>opposite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>liwc_OtherP</td>\n",
       "      <td>0.05</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>liwc_WC</td>\n",
       "      <td>0.05</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>hedge_D_ratio</td>\n",
       "      <td>0.05</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>liwc_Culture</td>\n",
       "      <td>0.01</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>liwc_Clout</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>liwc_Analytic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>liwc_want</td>\n",
       "      <td>0.01</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emotion_hartmann_anger_ratio</td>\n",
       "      <td>0.01</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature  effective ineffective_conservative  \\\n",
       "105                 hedge_I_ratio                                0.09   \n",
       "32                  hedge_E_ratio                               -0.07   \n",
       "104                   liwc_OtherP                                0.05   \n",
       "102                       liwc_WC                                0.05   \n",
       "103                 hedge_D_ratio                                0.05   \n",
       "..                            ...                                 ...   \n",
       "43                   liwc_Culture                                0.01   \n",
       "42                     liwc_Clout                               -0.01   \n",
       "41                  liwc_Analytic                                0.01   \n",
       "40                      liwc_want                                0.01   \n",
       "0    emotion_hartmann_anger_ratio                                0.01   \n",
       "\n",
       "            label  \n",
       "105          same  \n",
       "32       opposite  \n",
       "104          same  \n",
       "102          same  \n",
       "103          same  \n",
       "..            ...  \n",
       "43           same  \n",
       "42           same  \n",
       "41           same  \n",
       "40           same  \n",
       "0    conservative  \n",
       "\n",
       "[92 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideology = \"conservative\"\n",
    "\n",
    "sign_features_df = pd.read_csv(\"../data/significant_test/summary_training_effect.csv\")\n",
    "sign_features_df = sign_features_df[(sign_features_df[\"label\"] == ideology) | (sign_features_df[\"label\"] == \"same\") | (sign_features_df[\"label\"] == \"opposite\")]\n",
    "col = f\"absolute_effect_{ideology}\"\n",
    "sign_features_df = sign_features_df.sort_values(by=[col], ascending=False)\n",
    "sign_features_df[[\"feature\", f\"effective ineffective_{ideology}\", \"label\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler, MaxAbsScaler, PowerTransformer, QuantileTransformer, Normalizer\n",
    "\n",
    "def get_top_features(ideology: str):\n",
    "    sign_features_df = pd.read_csv(\"../data/significant_test/summary_training_effect.csv\")\n",
    "    sign_features_df = sign_features_df[(sign_features_df[\"label\"] == ideology) | (sign_features_df[\"label\"] == \"same\") | (sign_features_df[\"label\"] == \"opposite\")]\n",
    "    col = f\"absolute_effect_{ideology}\"\n",
    "    sign_features_df = sign_features_df.sort_values(by=[col], ascending=False)\n",
    "    return sign_features_df[[\"feature\", f\"effective ineffective_{ideology}\", \"label\"]]\n",
    "\n",
    "def _add_score_features(row, ideology, top_features):\n",
    "    feature_col_name = f\"effective ineffective_{ideology}\"\n",
    "    features_score: float = 0.0\n",
    "    for _, feature_row in top_features.iterrows():\n",
    "        feature_name = feature_row['feature']\n",
    "        features_score = features_score +  (row[feature_name] * feature_row[feature_col_name] )\n",
    "    row['features_score'] = features_score\n",
    "    return row\n",
    "\n",
    "\n",
    "def score_training_features(ideology: str) -> pd.DataFrame:\n",
    "     \n",
    "    top_features: pd.DataFrame = get_top_features(ideology)\n",
    "    _, data = iesta.machine_learning.dataloader.load_training_features_df(ideology.capitalize())\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    columns_to_normalize = top_features[\"feature\"].values.tolist()\n",
    "    data[columns_to_normalize] = scaler.fit_transform(data[columns_to_normalize])\n",
    "    \n",
    "    data = data.apply(_add_score_features, axis=1, args=(ideology, top_features,))\n",
    "\n",
    "    data = data.sort_values(by=['features_score'], ascending=False)\n",
    "    return data\n",
    "\n",
    "def generate_training_w_scores(ideology:str = \"liberal\", strategy: str = \"feature-based\"):\n",
    "    if strategy == \"feature-based\":\n",
    "        return score_training_features(ideology)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iesta        INFO     File already created. Loading file...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2135: ../data/extracted_features//Liberal_style-features_5000/Liberal_batch5000_6_style-features.parquet\n",
      "35: ../data/extracted_features//Liberal_transformer-features_100/Liberal_batch100_272_transformer-features.parquet\n",
      "excluding very long texts\n"
     ]
    }
   ],
   "source": [
    "liberal_w_feature_score = generate_training_w_scores(ideology = \"liberal\", strategy=\"feature-based\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_box(_df):\n",
    "    #_df = liberal_w_feature_score#[liberal_w_feature_score[\"features_score\"]< 1.5]\n",
    "    # Assuming you already have the DataFrame _df with the columns 'features_score' and 'effect'\n",
    "\n",
    "    # Use the groupby function to group the data by the 'effect' column\n",
    "    grouped_data = _df.groupby('effect')['features_score']\n",
    "\n",
    "    # Convert the grouped data into a list of lists to pass to the boxplot function\n",
    "    data_to_plot = [group.values.tolist() for name, group in grouped_data]\n",
    "\n",
    "    # Create the boxplot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot(data_to_plot, labels=grouped_data.groups.keys())\n",
    "    plt.xlabel('Effect')\n",
    "    plt.ylabel('Features Score')\n",
    "    plt.title('Boxplot of Features Score for each Effect')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_box1(_df):\n",
    "    \n",
    "    # Set the figure size for the plot (optional but can be useful)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Use Seaborn's boxplot to plot 'features_score' for each 'effect'\n",
    "    sns.boxplot(x='effect', y='features_score', data=_df)\n",
    "\n",
    "    # Add numbers on the plot\n",
    "    ax = sns.stripplot(x='effect', y='features_score', data=_df, color=\"black\", size=4, jitter=True)\n",
    "\n",
    "    # Set plot labels\n",
    "    plt.xlabel('Effect', fontsize=12)\n",
    "    plt.ylabel('Features Score', fontsize=12)\n",
    "    plt.title('Boxplot of Features Score for each Effect', fontsize=14)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_w_feature_score = generate_training_w_scores(ideology = \"conservative\", strategy=\"feature-based\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save(df_w_score, ideology):\n",
    "    for effect in [\"effective\", \"ineffective\"]:\n",
    "        df = df_w_score[df_w_score[\"effect\"] == effect]\n",
    "        df = df[[\"effect\", \"cleaned_text\", \"features_score\"]]\n",
    "        ascending = effect == \"ineffective\"\n",
    "        print(f\"Saving for {effect} with ascending {ascending}\")\n",
    "        df = df.sort_values(by=[\"features_score\"], ascending=ascending)\n",
    "        df.to_parquet(f\"../data/training/strategy_feature_based/{ideology}_{effect}.parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(f\"../data/training/strategy_feature_based/liberal_effective.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save(liberal_w_feature_score, \"liberal\")\n",
    "\n",
    "save(cons_w_feature_score, \"conservative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_features(\"conservative\")['feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from umap import UMAP\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# PREPARE DATA FOR pca\n",
    "\n",
    "\n",
    "# X_norm = (X - X.min())/(X.max() - X.min())\n",
    "# X_standardized = StandardScaler().fit_transform(X)\n",
    "def plot_reducer(df, ideology, reducer :str = \"PCA\", **kwargs):\n",
    "\n",
    "    top_features = get_top_features(ideology)['feature'].tolist()\n",
    "    X = df.loc[:, top_features].values\n",
    "\n",
    "    # Apply Standard Scaling\n",
    "    sc = StandardScaler()\n",
    "    X = sc.fit_transform(X)\n",
    "    # pd.DataFrame(X,columns=feature).head()\n",
    "    # Define two components\n",
    "    if reducer == \"PSA\":\n",
    "        reducer = PCA(n_components=2)\n",
    "    elif reducer == \"UMAP\":\n",
    "        reducer = UMAP(n_components=2, **kwargs)\n",
    "    elif reducer == \"TSNE\":\n",
    "        reducer = TSNE(n_components=2)\n",
    "\n",
    "    principalComponents = reducer.fit_transform(X)\n",
    "    principalDf = pd.DataFrame(\n",
    "        data=principalComponents,\n",
    "        columns=[\"component 1\", \"component 2\"],\n",
    "    )\n",
    "    # principalDf.head()\n",
    "    finalDf = pd.concat([principalDf, df[[\"effect\"]]], axis=1)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.set_xlabel(\"Principal Component 1\", fontsize=15)\n",
    "    ax.set_ylabel(\"Principal Component 2\", fontsize=15)\n",
    "    ax.set_title(ideology, fontsize=20)\n",
    "    targets = list(df.effect.unique())\n",
    "    colors = [\"b\", \"g\", \"y\", \"m\"]  # sns.color_palette('deep')[:len(targets)]\n",
    "    sorted_df = finalDf.sort_values(by=[\"component 1\", \"component 2\"], ascending=False)\n",
    "    top_examples= {}\n",
    "    for target, color in zip(targets, colors):\n",
    "        indicesToKeep = finalDf[\"effect\"] == target\n",
    "\n",
    "        \n",
    "        top_examples[target] = sorted_df[sorted_df[\"effect\"] == target]\n",
    "        \n",
    "        ax.scatter(\n",
    "            finalDf.loc[indicesToKeep, \"component 1\"],\n",
    "            finalDf.loc[indicesToKeep, \"component 2\"],\n",
    "            c=color,\n",
    "            s=50,\n",
    "        )\n",
    "        ax.xaxis.label.set_color(\"white\")\n",
    "        ax.yaxis.label.set_color(\"white\")\n",
    "        ax.title.set_color(\"white\")\n",
    "        ax.tick_params(axis=\"x\", colors=\"white\")\n",
    "        ax.tick_params(axis=\"y\", colors=\"white\")\n",
    "        ax.legend(targets)\n",
    "        ax.grid()\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.show()\n",
    "\n",
    "    return top_examples\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [5, 10, 15, 20]\n",
    "n_components = 2\n",
    "metrics = [\"euclidean\", \"manhattan\", \"cosine\", \"correlation\", \"mahalanobis\", \"jaccard\"]\n",
    "\n",
    "\n",
    "for metric, n_neighbor in [(x, y) for x in metrics for y in n_neighbors]:\n",
    "    params = {\"n_neighbors\": n_neighbor,\n",
    "               \"metric\": metric,}\n",
    "    \n",
    "    print(f\"*** FOR n_neighbor {n_neighbor} and metric {metric}:\")\n",
    "    _ = plot_reducer(feature_dfs[\"liberal\"], \"liberal\", \"UMAP\", **params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_reducer(feature_dfs[\"liberal\"], \"liberal\", \"TSNE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_reducer(feature_dfs[\"liberal\"], \"liberal\", \"UMAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_examples[\"ineffective\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iesta_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33b81bc8650a3643e935a2ab53ff66219719f7237086cfdf4850911b872414e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
