{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a2706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 -m venv elbaff_iesta_venv --prompt=\"elbaff_iesta_venv\"\n",
    "# source elbaff_iesta_venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56c37892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpaf.annotator.pipeline.pipeline_base import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import importlib\n",
    "\n",
    "import iesta.loader as loader\n",
    "import iesta.properties as prop  \n",
    "import iesta.processor as proc  \n",
    "import iesta.feature_extractor as fe\n",
    "from iesta.machine_learning.dataloader import IESTAData, METHODOLOGY\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "721f7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_each_dataloader = IESTAData(ideology=prop.CONSERVATIVE_IDEOLOGY, methodology=METHODOLOGY.EACH)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d760d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\users\\elba_ro\\documents\\projects\\conf22-style-transfer\\iesta\\..\\data\\splitted_conservative_debate_arguments_effect_test0.3_random2.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textmining-utility INFO     File already created. Loading file...\n"
     ]
    }
   ],
   "source": [
    "conservative_training_each_df, conservative_data_path = conservative_each_dataloader.get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05394a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_each_dataloader.pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e10a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_each_dataloader.pivot_binary_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd481a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conservative_training_each_df  = conservative_each_dataloader.data_df[conservative_each_dataloader.data_df[\"split\"] == \"training\"].copy()\n",
    "len(conservative_training_each_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e11a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conservative_training_each_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee00c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb2d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "class TransformerBasedFeaturePipeline(Pipeline):\n",
    "    \n",
    "\n",
    "    def __init__(self,\n",
    "                 input= None,\n",
    "                 load_default_pipe_configs = True,\n",
    "                 extended_pipe_configs:dict = None,\n",
    "                 save_output= False,\n",
    "                 out_path = None,\n",
    "                 argument_col:str = \"cleaned_text\"\n",
    "                 ):\n",
    "        super().__init__(input,\n",
    "                 load_default_pipe_configs,\n",
    "                 extended_pipe_configs,\n",
    "                 save_output,\n",
    "                 out_path)\n",
    "        self.argument_col= argument_col\n",
    "        \n",
    "    def process_input(self) -> list:\n",
    "        processed = []\n",
    "        txt_df = self.input[[\"id\", self.argument_col]].copy()\n",
    "        txt_df =txt_df.rename(columns={\"id\": \"input_id\", self.argument_col: \"text\"},)\n",
    "        \n",
    "        for idx, row in txt_df.iterrows():\n",
    "            processed.append((row.text, {\"input_id\": row.input_id}))\n",
    "\n",
    "        return processed\n",
    "    \n",
    "    \n",
    "    def init_and_run(self):\n",
    "        self.add_annotation_pipe(name = \"sentencizer\", save_output= False,is_spacy=True, is_native=True)\n",
    "        self.add_annotation_pipe(name = \"EmotionPipeOrchestrator\", save_output= True, is_spacy=True)\n",
    "        #self.add_annotation_pipe(name = \"HedgePipeOrchestrator\",   save_output= True, is_spacy=True)\n",
    "        self.add_annotation_pipe(name = \"ToxicityOrchestrator\",    save_output= True, is_spacy=True)\n",
    "        self.init_pipe_stack()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec82d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpaf.util.timer import Timer\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "\n",
    "batch_size = 3000 \n",
    "counter = 1\n",
    "\n",
    "\n",
    "\n",
    "parquet_file = pq.ParquetFile(conservative_data_path)\n",
    "pipeline = TransformerBasedFeaturePipeline(save_output= True)\n",
    "pipeline.init_and_run()\n",
    "\n",
    "for batch in parquet_file.iter_batches(batch_size=batch_size):\n",
    "\n",
    "    batch_df = batch.to_pandas()\n",
    "    \n",
    "    print(f\"processing batch {counter}\")\n",
    "    \n",
    "    ## RESET\n",
    "    pipeline.reset_input_output()\n",
    "    pipeline.out_path = f\"conservative_batch{counter}_emotion-toxic.parquet\"\n",
    "    \n",
    "    pipeline.set_input(batch_df)\n",
    "    t = Timer(name=f\"chunck_{counter}\")\n",
    "    t.start()\n",
    "    \n",
    "    pipeline.annotate()\n",
    "    pipeline.save()\n",
    "    t.stop()\n",
    "    #pipeline.out_df.head()\n",
    "    counter = counter+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c30a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d48b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "test_df = pd.DataFrame([{\"id\": 1, \"cleaned_text\": \"This is a very hard time, I am devastated! This a happy sentence 2.\"},\n",
    "                         {\"id\": 2, \"cleaned_text\": \"You can not get your tiny brain to work on this so stupid!!\"},\n",
    "                         {\"id\": 3, \"cleaned_text\": \"The amonium Nitrate was sitting there for ages.\"},\n",
    "                         {\"id\": 4, \"cleaned_text\": \"I love you and I love how you look\"}\n",
    "                       ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd90d486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline = TransformerBasedFeaturePipeline(save_output= True,\n",
    "                 \"../data/extracted_features/features_conservative_training_each.parquet\")\n",
    "#pipeline.set_input(conservative_training_each_df)\n",
    "pipeline.set_input(test_df)\n",
    "pipeline.init_and_run()\n",
    "pipeline.out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b54cdc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "33b81bc8650a3643e935a2ab53ff66219719f7237086cfdf4850911b872414e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
