{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a2706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python3 -m venv elbaff_iesta_venv --prompt=\"elbaff_iesta_venv\"\n",
    "#source elbaff_iesta_venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c37892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpaf.annotator.pipeline.pipeline_base import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import iesta.loader as loader\n",
    "import iesta.properties as prop  \n",
    "import iesta.processor as proc  \n",
    "import iesta.feature_extractor as fe\n",
    "from iesta.machine_learning.dataloader import IESTAData, METHODOLOGY\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721f7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_each_dataloader = IESTAData(ideology=prop.CONSERVATIVE_IDEOLOGY, methodology=METHODOLOGY.EACH)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d760d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_training_each_df, conservative_data_path = conservative_each_dataloader.get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05394a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_each_dataloader.pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e10a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_each_dataloader.pivot_binary_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd481a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conservative_training_each_df  = conservative_each_dataloader.data_df[conservative_each_dataloader.data_df[\"split\"] == \"training\"].copy()\n",
    "len(conservative_training_each_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e11a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conservative_training_each_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee00c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb2d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "class TransformerBasedFeaturePipeline(Pipeline):\n",
    "    \n",
    "\n",
    "    def __init__(self,\n",
    "                 input= None,\n",
    "                 load_default_pipe_configs = True,\n",
    "                 extended_pipe_configs:dict = None,\n",
    "                 save_output= False,\n",
    "                 out_path = None,\n",
    "                 argument_col:str = \"cleaned_text\"\n",
    "                 ):\n",
    "        super().__init__(input,\n",
    "                 load_default_pipe_configs,\n",
    "                 extended_pipe_configs,\n",
    "                 save_output,\n",
    "                 out_path)\n",
    "        self.argument_col= argument_col\n",
    "        \n",
    "    def process_input(self) -> list:\n",
    "        processed = []\n",
    "        txt_df = self.input[[\"id\", self.argument_col]].copy()\n",
    "        txt_df =txt_df.rename(columns={\"id\": \"input_id\", self.argument_col: \"text\"},)\n",
    "        \n",
    "        for idx, row in txt_df.iterrows():\n",
    "            processed.append((row.text, {\"input_id\": row.input_id}))\n",
    "\n",
    "        return processed\n",
    "    \n",
    "    \n",
    "    def init_and_run(self):\n",
    "        self.add_annotation_pipe(name = \"sentencizer\", save_output= False,is_spacy=True, is_native=True)\n",
    "        self.add_annotation_pipe(name = \"EmotionPipeOrchestrator\", save_output= True, is_spacy=True)\n",
    "        #self.add_annotation_pipe(name = \"HedgePipeOrchestrator\",   save_output= True, is_spacy=True)\n",
    "        self.add_annotation_pipe(name = \"ToxicityOrchestrator\",    save_output= True, is_spacy=True)\n",
    "        self.init_pipe_stack()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ec82d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nlpaf        INFO     adding pipe with name EmotionPipeOrchestrator\n",
      "nlpaf        INFO     orchestrator was initialized successfully\n",
      "nlpaf        INFO     adding pipe with code emotion_hartmann_component\n",
      "nlpaf        INFO     adding pipe with name ToxicityOrchestrator\n",
      "nlpaf        INFO     orchestrator was initialized successfully\n",
      "nlpaf        INFO     adding pipe with code toxicity_component\n",
      "nlpaf        INFO     Defining pipe default and spacy stacks\n",
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "nlpaf        INFO     Pipes are ['sentencizer', 'emotion_hartmann_component', 'toxicity_component']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping batch 1_100\n",
      "skipping batch 2_100\n",
      "processing batch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]nlpaf        INFO     saving annotations of Pipe(name='EmotionPipeOrchestrator', save_output=True, is_spacy=True, is_native=False, pipe_id_or_func='emotion_hartmann_component')\n",
      "nlpaf        INFO     saving annotations of Pipe(name='ToxicityOrchestrator', save_output=True, is_spacy=True, is_native=False, pipe_id_or_func='toxicity_component')\n",
      "100%|██████████| 3/3 [00:00<00:00, 61.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunck_3 Elapsed time: 95.3526 seconds\n",
      "chunck_3 Elapsed time: 95.3526 seconds\n",
      "processing batch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]nlpaf        INFO     saving annotations of Pipe(name='EmotionPipeOrchestrator', save_output=True, is_spacy=True, is_native=False, pipe_id_or_func='emotion_hartmann_component')\n",
      "nlpaf        INFO     saving annotations of Pipe(name='ToxicityOrchestrator', save_output=True, is_spacy=True, is_native=False, pipe_id_or_func='toxicity_component')\n",
      "100%|██████████| 3/3 [00:00<00:00, 58.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunck_4 Elapsed time: 71.1144 seconds\n",
      "chunck_4 Elapsed time: 71.1144 seconds\n",
      "processing batch 5\n"
     ]
    }
   ],
   "source": [
    "from nlpaf.util.timer import Timer\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "counter = 1\n",
    "\n",
    "\n",
    "\n",
    "parquet_file = pq.ParquetFile(conservative_data_path)\n",
    "pipeline = TransformerBasedFeaturePipeline(save_output= True)\n",
    "pipeline.init_and_run()\n",
    "out_file = \"../data/extracted_features/conservative_batch{}_{}_emotion-toxic.parquet\"\n",
    "for batch in parquet_file.iter_batches(batch_size=batch_size):\n",
    "    file = out_file.format(counter, batch_size)\n",
    "    if  Path(file).is_file():\n",
    "        print(f\"skipping batch {counter}_{batch_size}\")\n",
    "        counter = counter+1\n",
    "        continue\n",
    "    batch_df = batch.to_pandas()\n",
    "    \n",
    "    print(f\"processing batch {counter}\")\n",
    "    \n",
    "    ## RESET\n",
    "    pipeline.reset_input_output()\n",
    "    pipeline.out_path = file\n",
    "    \n",
    "    pipeline.set_input(batch_df)\n",
    "    t = Timer(name=f\"chunck_{counter}\")\n",
    "    t.start()\n",
    "    \n",
    "    pipeline.annotate()\n",
    "    pipeline.save()\n",
    "    t.stop()\n",
    "    #pipeline.out_df.head()\n",
    "    counter = counter+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c30a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "model_path = 'SkolkovoInstitute/roberta_toxicity_classifier'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "_nlp = pipeline('text-classification',model=model,tokenizer=tokenizer,truncation=True, top_k=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nlpaf\n",
    "#spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp =spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "nlp.add_pipe(\"emotion_hartmann_component\")\n",
    "out = list(nlp.pipe([\"asda\" , \"abc\"],  n_process=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d48b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "test_df = pd.DataFrame([{\"id\": 1, \"cleaned_text\": \"This is a very hard time, I am devastated! This a happy sentence 2.\"},\n",
    "                         {\"id\": 2, \"cleaned_text\": \"You can not get your tiny brain to work on this so stupid!!\"},\n",
    "                         {\"id\": 3, \"cleaned_text\": \"The amonium Nitrate was sitting there for ages.\"},\n",
    "                         {\"id\": 4, \"cleaned_text\": \"I love you and I love how you look\"}\n",
    "                       ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd90d486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline = TransformerBasedFeaturePipeline(save_output= True,\n",
    "                 \"../data/extracted_features/features_conservative_training_each.parquet\")\n",
    "#pipeline.set_input(conservative_training_each_df)\n",
    "pipeline.set_input(test_df)\n",
    "pipeline.init_and_run()\n",
    "pipeline.out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b54cdc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e56de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "33b81bc8650a3643e935a2ab53ff66219719f7237086cfdf4850911b872414e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
