{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "507a2706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 -m venv elbaff_iesta_venv --prompt=\"elbaff_iesta_venv\"\n",
    "# source elbaff_iesta_venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a746c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers.utils import logging\n",
    "from transformers import pipeline\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "model_path = 'SkolkovoInstitute/roberta_toxicity_classifier'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "transformer_nlp = pipeline('text-classification',\n",
    "                                model=model,\n",
    "                                tokenizer=tokenizer,\n",
    "                                truncation=True, top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0fb46c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.ner import NERModel, NERArgs\n",
    "ner_args = NERArgs()\n",
    "ner_args.silent = True\n",
    "model = NERModel(\n",
    "    'bert',\n",
    "    'jeniakim/hedgehog',\n",
    "    use_cuda=False,\n",
    "    labels=[\"C\", \"D\", \"E\", \"I\", \"N\"], args=ner_args\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a4724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([\"This is a text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad208c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neutral', 'score': 0.9998080134391785},\n",
       " {'label': 'toxic', 'score': 0.00019199376401957124}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit\n",
    "transformer_nlp(\"This is a toxic sentence!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56c37892",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textmining_utility'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextmining_utility\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textmining_utility'"
     ]
    }
   ],
   "source": [
    "from textmining_utility.annotator.pipeline.pipeline_base import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import importlib\n",
    "\n",
    "import iesta.loader as loader\n",
    "import iesta.properties as prop  \n",
    "import iesta.processor as proc  \n",
    "import iesta.feature_extractor as fe\n",
    "from iesta.machine_learning.dataloader import IESTAData, METHODOLOGY\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "721f7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberal_each_dataloader = IESTAData(ideology=prop.LIBERAL_IDEOLOGY, methodology=METHODOLOGY.EACH)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d760d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textmining-utility INFO     File already created. Loading file...\n",
      "textmining-utility INFO     File already created. Loading file...\n"
     ]
    }
   ],
   "source": [
    "liberal_each_dataloader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05394a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>effect</th>\n",
       "      <th>effective</th>\n",
       "      <th>ineffective</th>\n",
       "      <th>okay</th>\n",
       "      <th>provocative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>248</td>\n",
       "      <td>5349</td>\n",
       "      <td>969</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training</th>\n",
       "      <td>1722</td>\n",
       "      <td>37713</td>\n",
       "      <td>6835</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>613</td>\n",
       "      <td>10749</td>\n",
       "      <td>1828</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "effect      effective  ineffective  okay  provocative\n",
       "split                                                \n",
       "test              248         5349   969           92\n",
       "training         1722        37713  6835          522\n",
       "validation        613        10749  1828          204"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liberal_each_dataloader.pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e10a31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>binary_effect</th>\n",
       "      <th>effective</th>\n",
       "      <th>ineffective</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>248</td>\n",
       "      <td>6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training</th>\n",
       "      <td>1722</td>\n",
       "      <td>45070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>613</td>\n",
       "      <td>12781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "binary_effect  effective  ineffective\n",
       "split                                \n",
       "test                 248         6410\n",
       "training            1722        45070\n",
       "validation           613        12781"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liberal_each_dataloader.pivot_binary_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd481a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46792"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liberal_training_each_df  = liberal_each_dataloader.data_df[liberal_each_dataloader.data_df[\"split\"] == \"training\"].copy()\n",
    "len(liberal_training_each_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e11a5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'debate_id',\n",
       " 'p_name',\n",
       " 'effects',\n",
       " 'effect_count',\n",
       " 'top_effect',\n",
       " 'effect',\n",
       " 'category',\n",
       " 'round',\n",
       " 'argument',\n",
       " 'split',\n",
       " 'binary_effect']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liberal_training_each_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7efb2d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "class TransformerBasedFeaturePipeline(Pipeline):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input= None,\n",
    "                 load_default_pipe_configs = True,\n",
    "                 extended_pipe_configs:dict = None,\n",
    "                 save_output= False,\n",
    "                 out_path = None,\n",
    "                 argument_col:str = \"argument\"\n",
    "                 ):\n",
    "        super().__init__(input,\n",
    "                 load_default_pipe_configs,\n",
    "                 extended_pipe_configs,\n",
    "                 save_output,\n",
    "                 out_path)\n",
    "        self.argument_col= argument_col\n",
    "        \n",
    "    def process_input(self) -> list:\n",
    "        processed = []\n",
    "        txt_df = self.input[[\"id\", self.argument_col]].copy()\n",
    "        txt_df =txt_df.rename(columns={\"id\": \"input_id\", self.argument_col: \"text\"},)\n",
    "        \n",
    "        for idx, row in txt_df.iterrows():\n",
    "            processed.append((row.text, {\"input_id\": row.input_id}))\n",
    "\n",
    "        return processed\n",
    "\n",
    "    def init_and_run(self):\n",
    "        \n",
    "        self.add_annotation_pipe(name = \"senter\",                  save_output= False,is_spacy=True, is_native=True)\n",
    "        self.add_annotation_pipe(name = \"EmotionPipeOrchestrator\", save_output= True, is_spacy=True)\n",
    "        self.add_annotation_pipe(name = \"HedgePipeOrchestrator\",   save_output= True, is_spacy=True)\n",
    "        self.add_annotation_pipe(name = \"ToxicityOrchestrator\",    save_output= True, is_spacy=True)\n",
    "\n",
    "        # annotate the input\n",
    "        #self.set_spacy_language_model(\"en_core_web_md\")\n",
    "        self.annotate()\n",
    "        # save annotations when \"save_output\" is set to True\n",
    "        self.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecec3c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "test_df = pd.DataFrame([{\"id\": 1, \"argument\": \"This is a very hard time, I am devastated!\"},\n",
    "                         {\"id\": 2, \"argument\": \"You can not get your tiny brain to work on this so stupid!!\"},\n",
    "                         {\"id\": 3, \"argument\": \"The amonium Nitrate was sitting there for ages.\"},\n",
    "                         {\"id\": 4, \"argument\": \"I love you and I love how you look\"}\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TransformerBasedFeaturePipeline(save_output= True,\n",
    "                 out_path = \"../data/extracted_features/test.parquet\")\n",
    "pipeline.set_input(test_df)\n",
    "#pipeline.set_input(test_df)\n",
    "pipeline.init_and_run()\n",
    "pipeline.out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd90d486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textmining-utility INFO     adding pipe with name EmotionPipeOrchestrator\n",
      "textmining-utility INFO     adding pipe with name EmotionPipeOrchestrator\n",
      "textmining-utility DEBUG    loading textmining_utility.annotator.pipe.linguistic.emotion\n",
      "textmining-utility DEBUG    loading textmining_utility.annotator.pipe.linguistic.emotion\n",
      "textmining-utility INFO     orchestrator was initialized successfully\n",
      "textmining-utility INFO     orchestrator was initialized successfully\n",
      "textmining-utility INFO     adding pipe with code emotion_hartmann_component\n",
      "textmining-utility INFO     adding pipe with code emotion_hartmann_component\n",
      "textmining-utility INFO     adding pipe with name HedgePipeOrchestrator\n",
      "textmining-utility INFO     adding pipe with name HedgePipeOrchestrator\n",
      "textmining-utility DEBUG    loading textmining_utility.annotator.pipe.linguistic.hedge\n",
      "textmining-utility DEBUG    loading textmining_utility.annotator.pipe.linguistic.hedge\n",
      "textmining-utility INFO     orchestrator was initialized successfully\n",
      "textmining-utility INFO     orchestrator was initialized successfully\n",
      "textmining-utility INFO     adding pipe with code hedge_component\n",
      "textmining-utility INFO     adding pipe with code hedge_component\n",
      "textmining-utility INFO     adding pipe with name ToxicityOrchestrator\n",
      "textmining-utility INFO     adding pipe with name ToxicityOrchestrator\n",
      "textmining-utility DEBUG    loading textmining_utility.annotator.pipe.linguistic.toxicity\n",
      "textmining-utility DEBUG    loading textmining_utility.annotator.pipe.linguistic.toxicity\n",
      "textmining-utility INFO     orchestrator was initialized successfully\n",
      "textmining-utility INFO     orchestrator was initialized successfully\n",
      "textmining-utility INFO     adding pipe with code toxicity_component\n",
      "textmining-utility INFO     adding pipe with code toxicity_component\n",
      "textmining-utility INFO     Defining pipe default and spacy stacks\n",
      "textmining-utility INFO     Defining pipe default and spacy stacks\n",
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "pipeline = TransformerBasedFeaturePipeline(save_output= True,\n",
    "                 out_path = \"../data/extracted_features/features_liberal_training_each.parquet\")\n",
    "pipeline.set_input(liberal_training_each_df)\n",
    "#pipeline.set_input(test_df)\n",
    "pipeline.init_and_run()\n",
    "pipeline.out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a221ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.spacy_language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d48b68e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec82d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c30a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c1d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_transformers_df = pd.read_parquet(\"../data/extracted_features/features_liberal_training_each.parquet\")\n",
    "\n",
    "lib_transformers_df.head()\n",
    "lib_transformers_df['hedge_dominant'].value_counts().to_frame().plot(kind=\"bar\")\n",
    "lib_transformers_df['emotion_hartmann_label'].value_counts().to_frame().plot(kind=\"bar\")\n",
    "lib_transformers_df['toxicity_dominant'].value_counts().to_frame().plot(kind=\"bar\")\n",
    "\n",
    "lib_transformers_df[[\"emotion_hartmann_anger\",\n",
    "                     \"emotion_hartmann_disgust\",\n",
    "                    \"emotion_hartmann_fear\", \n",
    "                    \"emotion_hartmann_joy\",\n",
    "                    \"emotion_hartmann_neutral\",\n",
    "                    \"emotion_hartmann_surprise\",\n",
    "                    \"emotion_hartmann_sadness\"]].plot.hist(bins=12, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b54cdc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "5d911b662dcca331b664e839eaa84a9d76408cf32a476add886e2ab00bb2aa65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
