{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a2706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 -m venv elbaff_iesta_venv --prompt=\"elbaff_iesta_venv\"\n",
    "# source elbaff_iesta_venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56c37892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elba_ro/repos/conf22-style-transfer/iesta_venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/elba_ro/repos/conf22-style-transfer/iesta_venv/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n",
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "from nlpaf.annotator.pipeline.pipeline_base import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import iesta.properties as prop  \n",
    "from iesta.machine_learning.dataloader import IESTAData, METHODOLOGY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "721f7f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elba_ro/repos/conf22-style-transfer/iesta/../data/splitted_liberal_debate_arguments_effect_test0.3_random2.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>effect</th>\n",
       "      <th>effective</th>\n",
       "      <th>ineffective</th>\n",
       "      <th>okay</th>\n",
       "      <th>provocative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>248</td>\n",
       "      <td>5349</td>\n",
       "      <td>969</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training</th>\n",
       "      <td>1722</td>\n",
       "      <td>37713</td>\n",
       "      <td>6835</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>613</td>\n",
       "      <td>10749</td>\n",
       "      <td>1828</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "effect      effective  ineffective  okay  provocative\n",
       "split                                                \n",
       "test              248         5349   969           92\n",
       "training         1722        37713  6835          522\n",
       "validation        613        10749  1828          204"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "liberal_each_dataloader = IESTAData(ideology=prop.LIBERAL_IDEOLOGY, methodology=METHODOLOGY.EACH)\n",
    "liberal_training_each_df, liberal_data_path = liberal_each_dataloader.get_training_data()\n",
    "liberal_each_dataloader.pivot_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e10a31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>binary_effect</th>\n",
       "      <th>effective</th>\n",
       "      <th>ineffective</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>248</td>\n",
       "      <td>6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training</th>\n",
       "      <td>1722</td>\n",
       "      <td>45070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>613</td>\n",
       "      <td>12781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "binary_effect  effective  ineffective\n",
       "split                                \n",
       "test                 248         6410\n",
       "training            1722        45070\n",
       "validation           613        12781"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liberal_each_dataloader.pivot_binary_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e11a5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'debate_id',\n",
       " 'p_name',\n",
       " 'effects',\n",
       " 'effect_count',\n",
       " 'top_effect',\n",
       " 'effect',\n",
       " 'category',\n",
       " 'round',\n",
       " 'argument',\n",
       " 'split',\n",
       " 'cleaned_text',\n",
       " 'binary_effect']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liberal_training_each_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27403f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBasedFeaturePipeline(Pipeline):\n",
    "    \n",
    "\n",
    "    def __init__(self,\n",
    "                 input= None,\n",
    "                 load_default_pipe_configs = True,\n",
    "                 extended_pipe_configs:dict = None,\n",
    "                 save_output= False,\n",
    "                 out_path = None,\n",
    "                 argument_col:str = \"cleaned_text\"\n",
    "                 ):\n",
    "        super().__init__(input,\n",
    "                 load_default_pipe_configs,\n",
    "                 extended_pipe_configs,\n",
    "                 save_output,\n",
    "                 out_path)\n",
    "        self.argument_col= argument_col\n",
    "        \n",
    "    def process_input(self) -> list:\n",
    "        processed = []\n",
    "        txt_df = self.input[[\"id\", self.argument_col]].copy()\n",
    "        txt_df =txt_df.rename(columns={\"id\": \"input_id\", self.argument_col: \"text\"},)\n",
    "        \n",
    "        for idx, row in txt_df.iterrows():\n",
    "            processed.append((row.text, {\"input_id\": row.input_id}))\n",
    "\n",
    "        return processed\n",
    "    \n",
    "    \n",
    "    def init_and_run(self):\n",
    "        self.add_annotation_pipe(name = \"sentencizer\", save_output= False,is_spacy=True, is_native=True)\n",
    "        self.add_annotation_pipe(name = \"EmotionPipeOrchestrator\", save_output= True, is_spacy=True)\n",
    "        #self.add_annotation_pipe(name = \"HedgePipeOrchestrator\",   save_output= True, is_spacy=True)\n",
    "        self.add_annotation_pipe(name = \"ToxicityOrchestrator\",    save_output= True, is_spacy=True)\n",
    "        self.init_pipe_stack()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f22029e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nlpaf        INFO     adding pipe with name EmotionPipeOrchestrator\n",
      "nlpaf        INFO     orchestrator was initialized successfully\n",
      "nlpaf        INFO     adding pipe with code emotion_hartmann_component\n",
      "nlpaf        INFO     adding pipe with name ToxicityOrchestrator\n",
      "nlpaf        INFO     orchestrator was initialized successfully\n",
      "nlpaf        INFO     adding pipe with code toxicity_component\n",
      "nlpaf        INFO     Defining pipe default and spacy stacks\n",
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "nlpaf        INFO     Pipes are ['sentencizer', 'emotion_hartmann_component', 'toxicity_component']\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from nlpaf.util.timer import Timer\n",
    "from tqdm.auto import tqdm\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "import math\n",
    "from iesta import utils\n",
    "\n",
    "batch_size = 100\n",
    "counter = 1\n",
    "\n",
    "\n",
    "total = math.ceil(len(liberal_training_each_df)/(batch_size))\n",
    "\n",
    "parquet_file = pq.ParquetFile(liberal_data_path)\n",
    "pipeline = TransformerBasedFeaturePipeline(save_output= True)\n",
    "pipeline.init_and_run()\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "out_path = f\"../data/extracted_features/liberal_emotion-toxic_{batch_size}\"\n",
    "utils.create_folder(out_path)\n",
    "out_file = out_path+\"/liberal_batch{}_{}_emotion-toxic.parquet\"\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "for batch in tqdm(parquet_file.iter_batches(batch_size=batch_size), total=total ):\n",
    "    file = out_file.format(batch_size, counter, batch_size)\n",
    "    if  Path(file).is_file():\n",
    "        counter = counter+1\n",
    "        continue\n",
    "    batch_df = batch.to_pandas()\n",
    "        \n",
    "    ## RESET\n",
    "    pipeline.reset_input_output()\n",
    "    pipeline.out_path = file\n",
    "    \n",
    "    pipeline.set_input(batch_df)\n",
    "    t = Timer(name=f\"chunck_{counter}\")\n",
    "    t.start()\n",
    "    \n",
    "    pipeline.annotate()\n",
    "    pipeline.save()\n",
    "    t.stop()\n",
    "    #pipeline.out_df.head()\n",
    "    counter = counter+1\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b54cdc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c1d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_transformers_df = pd.read_parquet(\"../data/extracted_features/features_liberal_training_each.parquet\")\n",
    "\n",
    "lib_transformers_df.head()\n",
    "lib_transformers_df['hedge_dominant'].value_counts().to_frame().plot(kind=\"bar\")\n",
    "lib_transformers_df['emotion_hartmann_label'].value_counts().to_frame().plot(kind=\"bar\")\n",
    "lib_transformers_df['toxicity_dominant'].value_counts().to_frame().plot(kind=\"bar\")\n",
    "\n",
    "lib_transformers_df[[\"emotion_hartmann_anger\",\n",
    "                     \"emotion_hartmann_disgust\",\n",
    "                    \"emotion_hartmann_fear\", \n",
    "                    \"emotion_hartmann_joy\",\n",
    "                    \"emotion_hartmann_neutral\",\n",
    "                    \"emotion_hartmann_surprise\",\n",
    "                    \"emotion_hartmann_sadness\"]].plot.hist(bins=12, alpha=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('iesta_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "33b81bc8650a3643e935a2ab53ff66219719f7237086cfdf4850911b872414e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
